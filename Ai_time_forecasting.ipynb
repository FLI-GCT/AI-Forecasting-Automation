{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zezo-Elkafoury/AI-Forecasting-Automation/blob/main/Ai_time_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEkcUIX_heGq",
        "outputId": "2f9b3a83-f7ef-478b-ee59-da70940cf9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-llm7\n",
            "  Downloading langchain_llm7-2025.5.91116-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting tokeniser>=0.0.3 (from langchain-llm7)\n",
            "  Downloading tokeniser-2025.5.190811-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from langchain-llm7) (2.32.3)\n",
            "Collecting pydantic==2.11.3 (from langchain-llm7)\n",
            "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core==0.3.51 (from langchain-llm7)\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.51->langchain-llm7) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.51->langchain-llm7) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.51->langchain-llm7) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.51->langchain-llm7) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.51->langchain-llm7) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.51->langchain-llm7) (4.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.11.3->langchain-llm7) (0.7.0)\n",
            "Collecting pydantic-core==2.33.1 (from pydantic==2.11.3->langchain-llm7)\n",
            "  Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.11.3->langchain-llm7) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->langchain-llm7) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->langchain-llm7) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->langchain-llm7) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->langchain-llm7) (2025.6.15)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.51->langchain-llm7) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core==0.3.51->langchain-llm7) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core==0.3.51->langchain-llm7) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core==0.3.51->langchain-llm7) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core==0.3.51->langchain-llm7) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core==0.3.51->langchain-llm7) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core==0.3.51->langchain-llm7) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core==0.3.51->langchain-llm7) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core==0.3.51->langchain-llm7) (1.3.1)\n",
            "Downloading langchain_llm7-2025.5.91116-py3-none-any.whl (11 kB)\n",
            "Downloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.6/443.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokeniser-2025.5.190811-py3-none-any.whl (3.4 kB)\n",
            "Installing collected packages: tokeniser, pydantic-core, pydantic, langchain-core, langchain-llm7\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.65\n",
            "    Uninstalling langchain-core-0.3.65:\n",
            "      Successfully uninstalled langchain-core-0.3.65\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.25 requires langchain-core<1.0.0,>=0.3.58, but you have langchain-core 0.3.51 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.3.51 langchain-llm7-2025.5.91116 pydantic-2.11.3 pydantic-core-2.33.1 tokeniser-2025.5.190811\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-llm7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZsfKH9zWumG",
        "outputId": "e7287245-c48d-4442-e220-8ebdc3bf58d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.51)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.4.8 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 ormsgpack-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WD9D1Ia_USL",
        "outputId": "b4019e51-d16e-4827-9f60-8017499cb9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "python3-dev set to manually installed.\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libbz2-dev libpkgconf3 libreadline-dev\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n",
            "  libgvc6-plugins-gtk librsvg2-common libxdot4\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following packages will be REMOVED:\n",
            "  pkgconf r-base-dev\n",
            "The following NEW packages will be installed:\n",
            "  libgail-common libgail18 libgraphviz-dev libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libgvc6-plugins-gtk librsvg2-common libxdot4 pkg-config\n",
            "0 upgraded, 10 newly installed, 2 to remove and 35 not upgraded.\n",
            "Need to get 2,482 kB of archives.\n",
            "After this operation, 7,671 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 pkg-config amd64 0.29.2-1ubuntu3 [48.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libxdot4 amd64 2.42.2-6ubuntu0.1 [16.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgvc6-plugins-gtk amd64 2.42.2-6ubuntu0.1 [22.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgraphviz-dev amd64 2.42.2-6ubuntu0.1 [58.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Fetched 2,482 kB in 2s (1,569 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 10.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 126319 files and directories currently installed.)\n",
            "Removing r-base-dev (4.5.1-1.2204.0) ...\n",
            "dpkg: pkgconf: dependency problems, but removing anyway as you requested:\n",
            " libsndfile1-dev:amd64 depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libopencv-dev depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libmkl-dev:amd64 depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libjack-dev depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libgphoto2-dev:amd64 depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libglib2.0-dev:amd64 depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libfontconfig-dev:amd64 depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            "\n",
            "Removing pkgconf (1.8.0-1) ...\n",
            "Removing 'diversion of /usr/bin/pkg-config to /usr/bin/pkg-config.real by pkgconf'\n",
            "Removing 'diversion of /usr/share/aclocal/pkg.m4 to /usr/share/aclocal/pkg.real.m4 by pkgconf'\n",
            "Removing 'diversion of /usr/share/man/man1/pkg-config.1.gz to /usr/share/man/man1/pkg-config.real.1.gz by pkgconf'\n",
            "Removing 'diversion of /usr/share/pkg-config-crosswrapper to /usr/share/pkg-config-crosswrapper.real by pkgconf'\n",
            "Selecting previously unselected package pkg-config.\n",
            "(Reading database ... 126295 files and directories currently installed.)\n",
            "Preparing to unpack .../0-pkg-config_0.29.2-1ubuntu3_amd64.deb ...\n",
            "Unpacking pkg-config (0.29.2-1ubuntu3) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../1-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../2-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../3-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../4-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libxdot4:amd64.\n",
            "Preparing to unpack .../5-libxdot4_2.42.2-6ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxdot4:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Selecting previously unselected package libgvc6-plugins-gtk.\n",
            "Preparing to unpack .../6-libgvc6-plugins-gtk_2.42.2-6ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgvc6-plugins-gtk (2.42.2-6ubuntu0.1) ...\n",
            "Selecting previously unselected package libgraphviz-dev:amd64.\n",
            "Preparing to unpack .../7-libgraphviz-dev_2.42.2-6ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgraphviz-dev:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../8-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../9-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libxdot4:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Setting up pkg-config (0.29.2-1ubuntu3) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgvc6-plugins-gtk (2.42.2-6ubuntu0.1) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgraphviz-dev:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.3) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install python3-dev graphviz libgraphviz-dev pkg-config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TEOclthAUE1",
        "outputId": "69f4079b-0db7-45a0-de02-366302969f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygraphviz\n",
            "  Downloading pygraphviz-1.14.tar.gz (106 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.0/106.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pygraphviz\n",
            "  Building wheel for pygraphviz (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygraphviz: filename=pygraphviz-1.14-cp311-cp311-linux_x86_64.whl size=169714 sha256=94ec46b332185b932ea3aa72cdb9d4894ede6635de3381b226424bc3c2a8ddc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/5f/df/6fffd2a4353f26dbb0e3672a1baf070c124a1d74a5f9318279\n",
            "Successfully built pygraphviz\n",
            "Installing collected packages: pygraphviz\n",
            "Successfully installed pygraphviz-1.14\n"
          ]
        }
      ],
      "source": [
        "!sudo pip install pygraphviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkWb2dQxbuQc"
      },
      "source": [
        "# Loading the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rpv6Y_2bdAO"
      },
      "outputs": [],
      "source": [
        "from langchain_llm7 import ChatLLM7\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser,BaseOutputParser\n",
        "from langgraph.graph import StateGraph,END\n",
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "xZNIeV61ahgS",
        "outputId": "987206f5-b641-4b61-dc00-13f00c2359fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hey there! What's up?"
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "llm = ChatLLM7(\n",
        "    model='gpt-4.1-2025-04-14'\n",
        ")\n",
        "response = llm.invoke([HumanMessage(content=\"hello\")])\n",
        "Markdown(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm_L6cJzby2W"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FLxgTMFbp9u"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/oil.csv')\n",
        "df2=pd.read_csv('/content/Walmart_Sales.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M7yY8KXygvtw",
        "outputId": "1fc23f76-b0c3-4598-a494-16dbd47c46bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date  dcoilwtico\n",
              "0  2013-01-01         NaN\n",
              "1  2013-01-02       93.14\n",
              "2  2013-01-03       92.97\n",
              "3  2013-01-04       93.12\n",
              "4  2013-01-07       93.20"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-482e99ca-5251-4b29-9ba7-322afc9dce86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>dcoilwtico</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>93.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-01-03</td>\n",
              "      <td>92.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-01-04</td>\n",
              "      <td>93.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-01-07</td>\n",
              "      <td>93.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-482e99ca-5251-4b29-9ba7-322afc9dce86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-482e99ca-5251-4b29-9ba7-322afc9dce86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-482e99ca-5251-4b29-9ba7-322afc9dce86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f5ec9caf-9ee8-4733-8d22-4fa66b63a332\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5ec9caf-9ee8-4733-8d22-4fa66b63a332')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f5ec9caf-9ee8-4733-8d22-4fa66b63a332 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1218,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1218,\n        \"samples\": [\n          \"2015-01-28\",\n          \"2013-12-30\",\n          \"2013-03-01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dcoilwtico\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.630475729453224,\n        \"min\": 26.19,\n        \"max\": 110.62,\n        \"num_unique_values\": 998,\n        \"samples\": [\n          47.85,\n          45.23,\n          93.86\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "F0tZRd9osPgV",
        "outputId": "5792b7ba-fa9c-4c81-d1f8-e2c76f2892f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1175.000000\n",
              "mean       67.714366\n",
              "std        25.630476\n",
              "min        26.190000\n",
              "25%        46.405000\n",
              "50%        53.190000\n",
              "75%        95.660000\n",
              "max       110.620000\n",
              "Name: dcoilwtico, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dcoilwtico</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1175.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>25.630476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>26.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>46.405000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>53.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>95.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>110.620000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df['dcoilwtico'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SqPbXgWA0QMg",
        "outputId": "03ed64b9-1d37-4e98-dba6-e682f53cf47e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
              "0      1  05-02-2010    1643690.90             0        42.31       2.572   \n",
              "1      1  12-02-2010    1641957.44             1        38.51       2.548   \n",
              "2      1  19-02-2010    1611968.17             0        39.93       2.514   \n",
              "3      1  26-02-2010    1409727.59             0        46.63       2.561   \n",
              "4      1  05-03-2010    1554806.68             0        46.50       2.625   \n",
              "\n",
              "          CPI  Unemployment  \n",
              "0  211.096358         8.106  \n",
              "1  211.242170         8.106  \n",
              "2  211.289143         8.106  \n",
              "3  211.319643         8.106  \n",
              "4  211.350143         8.106  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e9db0b5-42d0-4d33-8ba1-5812030f0f41\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Holiday_Flag</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>05-02-2010</td>\n",
              "      <td>1643690.90</td>\n",
              "      <td>0</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>12-02-2010</td>\n",
              "      <td>1641957.44</td>\n",
              "      <td>1</td>\n",
              "      <td>38.51</td>\n",
              "      <td>2.548</td>\n",
              "      <td>211.242170</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>19-02-2010</td>\n",
              "      <td>1611968.17</td>\n",
              "      <td>0</td>\n",
              "      <td>39.93</td>\n",
              "      <td>2.514</td>\n",
              "      <td>211.289143</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>26-02-2010</td>\n",
              "      <td>1409727.59</td>\n",
              "      <td>0</td>\n",
              "      <td>46.63</td>\n",
              "      <td>2.561</td>\n",
              "      <td>211.319643</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>05-03-2010</td>\n",
              "      <td>1554806.68</td>\n",
              "      <td>0</td>\n",
              "      <td>46.50</td>\n",
              "      <td>2.625</td>\n",
              "      <td>211.350143</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e9db0b5-42d0-4d33-8ba1-5812030f0f41')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e9db0b5-42d0-4d33-8ba1-5812030f0f41 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e9db0b5-42d0-4d33-8ba1-5812030f0f41');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bcf02fbc-3b4a-4a3a-8255-35dbfcd13308\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bcf02fbc-3b4a-4a3a-8255-35dbfcd13308')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bcf02fbc-3b4a-4a3a-8255-35dbfcd13308 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 6435,\n  \"fields\": [\n    {\n      \"column\": \"Store\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 45,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          40,\n          26,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 143,\n        \"samples\": [\n          \"04-05-2012\",\n          \"18-06-2010\",\n          \"02-09-2011\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weekly_Sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 564366.6220536974,\n        \"min\": 209986.25,\n        \"max\": 3818686.45,\n        \"num_unique_values\": 6435,\n        \"samples\": [\n          1138800.32,\n          1304850.67,\n          1769296.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Holiday_Flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.444932875811585,\n        \"min\": -2.06,\n        \"max\": 100.14,\n        \"num_unique_values\": 3528,\n        \"samples\": [\n          51.13,\n          98.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fuel_Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4590197071928516,\n        \"min\": 2.472,\n        \"max\": 4.468,\n        \"num_unique_values\": 892,\n        \"samples\": [\n          2.84,\n          3.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CPI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39.35671229566413,\n        \"min\": 126.064,\n        \"max\": 227.2328068,\n        \"num_unique_values\": 2145,\n        \"samples\": [\n          184.613419,\n          214.1083654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unemployment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8758847818628084,\n        \"min\": 3.879,\n        \"max\": 14.313,\n        \"num_unique_values\": 349,\n        \"samples\": [\n          8.185,\n          7.804\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVpQL9FOkFKf"
      },
      "source": [
        "# Agent Structure\n",
        "\n",
        "- forecast_preprocessor => Bouncer (Router)\n",
        "\n",
        "- Forecast Code Generator => Generates Python code\n",
        "\n",
        "- Data Analyst Agent => Answers data related questions\n",
        "\n",
        "- Visulaization Function\n",
        "\n",
        "- Executing Code => Runs the Python code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDbNu4cPo8Wg"
      },
      "source": [
        "## 1- Forecast Preprocessor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zzmHJVzkHRK"
      },
      "outputs": [],
      "source": [
        "forecast_preprocessor_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are an expert question classifier for time series analysis. Your task is to:\n",
        "\n",
        "1. Analyze the user's question\n",
        "2. Determine if it requires:\n",
        "   - Data analysis/exploration (statistics, diagnostics, preparation)\n",
        "   - Time series forecasting (future predictions)\n",
        "3. Return JSON with your classification\n",
        "\n",
        "# CLASSIFICATION CRITERIA:\n",
        "- DATA ANALYSIS QUESTIONS:\n",
        "  - Requests for statistics, summaries, or data properties\n",
        "  - Questions about data quality (missing values, outliers)\n",
        "  - Time series diagnostics (stationarity, autocorrelation)\n",
        "  - Data transformations (rolling stats, differencing)\n",
        "\n",
        "- FORECASTING QUESTIONS:\n",
        "  - Requests for future predictions\n",
        "  - Questions about future trends\n",
        "  - Any question containing time horizons (next 30 days, etc.)\n",
        "\n",
        "# EXAMPLES:\n",
        "1. \"Show me monthly averages\" → DATA_ANALYSIS\n",
        "2. \"Forecast prices for next year\" → FORECAST\n",
        "3. \"Is this series stationary?\" → DATA_ANALYSIS\n",
        "4. \"Predict sales for Q4\" → FORECAST\n",
        "\n",
        "# OUTPUT FORMAT:\n",
        "{{\n",
        "    \"question_type\": \"DATA_ANALYSIS\" or \"FORECAST\",\n",
        "    \"reasoning\": \"brief explanation of your classification\"\n",
        "}}\n",
        "\n",
        "USER QUESTION: {question}\n",
        "\"\"\",\n",
        "    input_variables=[\"question\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbSs0vOClMwp"
      },
      "outputs": [],
      "source": [
        "forecast_preprocessor=forecast_preprocessor_prompt | llm | JsonOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7fJO41XpRbf"
      },
      "source": [
        "## 2- Forecast Code Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tbvkz2-wpSup"
      },
      "outputs": [],
      "source": [
        "forecast_code_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a forecasting expert. Given an input question and data provided as a dictionary from a SQL agent, your job is to write Python code to perform a forecast using the data as an input and determining a forecast horizon and which items to forecast.\n",
        "\n",
        "Return Python code in this format:\n",
        "\n",
        "```python\n",
        "def forecast_ts(data):\n",
        "    ...\n",
        "    return forecast_df\n",
        "\n",
        "\n",
        "# **IMPORTANT NOTES**:\n",
        "\n",
        " - Return a single function named forecast_ts that ingests a parameter containing \"data\", and outputs one data frame (forecast_df).\n",
        "\n",
        " - Do NOT re-write data inside the generated Python code.\n",
        "\n",
        " - Make sure to convert columns containing date information to Pandas datetime.\n",
        "\n",
        " - If no ID column is provided, make an ID column for use with the forecasts. Just use \"i\" for the ID.\n",
        "\n",
        "# **KEY DECISIONS FROM THE PROVIDED QUESTION**:\n",
        " - Which item should be forecasted? If none is provided, assume that all items should be forecasted (use a loop to do this).\n",
        "\n",
        " - How far into the future should the forecast be made?\n",
        "\n",
        " - If no forecast horizon is provided, determine a reasonable forecast horizon based on the data provided and its periodicity (example: if monthly data, forecast 12 months—a year's worth).\n",
        "\n",
        " - If more than one ID column is included in the data, consolidate into a single \"id_column\"\n",
        "\n",
        "**USEFUL FORECASTING FUNCTIONS**\n",
        "- use these functions to help you forecast. Make modified versions based on the input data\n",
        "\n",
        "# **ACCURACY-FOCUSED ENHANCEMENTS**:\n",
        "\n",
        "1. **Model Selection**:\n",
        "   - Always evaluate multiple models using time-series cross-validation\n",
        "   - Select model based on both MAE and MASE metrics\n",
        "   - Include confidence intervals in all forecasts\n",
        "\n",
        "2. **Data Preparation**:\n",
        "   - Automatic frequency detection with fallback logic\n",
        "   - Advanced stationarity testing (ADF/KPSS with auto-differencing)\n",
        "   - Multiple seasonality detection for weekly/monthly/quarterly patterns\n",
        "\n",
        "3. **Feature Engineering**:\n",
        "   - Automatic lag feature generation based on detected seasonality\n",
        "   - Fourier terms for all detected seasonal periods\n",
        "   - Rolling statistics with adaptive window sizes\n",
        "\n",
        "4. **Error Handling**:\n",
        "   - Graceful fallback for failed models\n",
        "   - Automatic data quality checks\n",
        "   - Validation of forecast outputs\n",
        "\n",
        "# **CORE REQUIREMENTS** (unchanged):\n",
        " - Single function named forecast_ts that ingests \"data\" and returns forecast_df\n",
        " - Preserve original data (no in-place modification)\n",
        " - Automatic datetime conversion\n",
        " - Default ID column 'i' if none provided\n",
        "\n",
        "def forecast_ts(data):\n",
        "    # ================================\n",
        "    # Wrap imports inside function\n",
        "    # ================================\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from xgboost import XGBRegressor\n",
        "    from statsmodels.tsa.arima.model import ARIMA\n",
        "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "    from sklearn.model_selection import TimeSeriesSplit\n",
        "    from prophet import Prophet\n",
        "    from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "    from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "    from tbats import TBATS\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    # ================================\n",
        "    # Enhanced Data Validation\n",
        "    # ================================\n",
        "    def validate_input_data(df):\n",
        "        \"Check data quality before processing\"\n",
        "        if len(df) < 12:\n",
        "            raise ValueError(\"Insufficient data (minimum 12 points required)\")\n",
        "        if df.isna().all().any():\n",
        "            raise ValueError(\"Column with all NaN values detected\")\n",
        "        return True\n",
        "\n",
        "    # ================================\n",
        "    # Advanced Frequency Detection\n",
        "    # ================================\n",
        "    def detect_frequency(df, date_col):\n",
        "        \"Robust frequency detection with fallback\"\n",
        "        try:\n",
        "            freq = pd.infer_freq(df[date_col])\n",
        "            if freq: return freq\n",
        "\n",
        "            diffs = df[date_col].diff().dropna().mode()\n",
        "            if len(diffs) > 0:\n",
        "                delta = diffs[0]\n",
        "                if pd.Timedelta(days=1) - pd.Timedelta(hours=6) <= delta <= pd.Timedelta(days=1) + pd.Timedelta(hours=6):\n",
        "                    return 'D'\n",
        "                elif pd.Timedelta(days=7) - pd.Timedelta(days=1) <= delta <= pd.Timedelta(days=7) + pd.Timedelta(days=1):\n",
        "                    return 'W'\n",
        "                elif pd.Timedelta(days=30) - pd.Timedelta(days=4) <= delta <= pd.Timedelta(days=30) + pd.Timedelta(days=4):\n",
        "                    return 'M'\n",
        "        except:\n",
        "            pass\n",
        "        return 'D'  # Default fallback\n",
        "\n",
        "    # ================================\n",
        "    # Enhanced Model Evaluation\n",
        "    # ================================\n",
        "    def evaluate_model(model_func, train, test, value_col, y_train):\n",
        "        \"Evaluate using both MAE and MASE\"\n",
        "        forecast = model_func(train, value_col)\n",
        "        mae = mean_absolute_error(test[value_col], forecast)\n",
        "\n",
        "        # Calculate MASE\n",
        "        naive_errors = np.abs(np.diff(y_train))\n",
        "        mase = mae / np.mean(naive_errors)\n",
        "\n",
        "        return {{'mae': mae, 'mase': mase}}\n",
        "\n",
        "    # ================================\n",
        "    # Multi-Seasonal Decomposition\n",
        "    # ================================\n",
        "    def detect_seasonality(df, value_col, freq):\n",
        "        \"Detect multiple seasonal patterns\"\n",
        "        periods = []\n",
        "        if freq == 'D':\n",
        "            # Check for weekly seasonality\n",
        "            if len(df) > 14:  # Need at least 2 weeks\n",
        "                periods.append(7)\n",
        "        elif freq == 'M':\n",
        "            periods.append(12)  # Yearly\n",
        "            if len(df) > 24:  # Need at least 2 years\n",
        "                periods.append(3)  # Quarterly\n",
        "        return periods\n",
        "\n",
        "    # ================================\n",
        "    # Enhanced Forecasting Models\n",
        "    # ================================\n",
        "    def forecast_with_prophet_enhanced(df, value_col, date_col, periods, seasonality):\n",
        "        \"Prophet with automatic seasonality detection\"\n",
        "        m = Prophet(\n",
        "            yearly_seasonality='auto',\n",
        "            weekly_seasonality='auto',\n",
        "            daily_seasonality='auto',\n",
        "            interval_width=0.95\n",
        "        )\n",
        "\n",
        "        # Add detected seasonal periods\n",
        "        for period in seasonality:\n",
        "            if period == 7:\n",
        "                m.add_seasonality(name='weekly', period=7, fourier_order=3)\n",
        "            elif period == 12:\n",
        "                m.add_seasonality(name='yearly', period=365.25, fourier_order=5)\n",
        "            elif period == 3:\n",
        "                m.add_seasonality(name='quarterly', period=91.25, fourier_order=3)\n",
        "\n",
        "        m.fit(df.rename(columns={{date_col: 'ds', value_col: 'y'}}))\n",
        "        future = m.make_future_dataframe(periods=periods, freq=detect_frequency(df, date_col))\n",
        "        forecast = m.predict(future)\n",
        "        return forecast[['date', 'yhat', 'yhat_lower', 'yhat_upper']].rename(\n",
        "        columns={{'yhat': 'forecast'}}\n",
        "\n",
        "    # ================================\n",
        "    # Main Forecasting Logic\n",
        "    # ================================\n",
        "    def generate_forecast(df, date_col, value_col, id_col, forecast_horizon):\n",
        "        \"Enhanced forecasting pipeline\"\n",
        "        try:\n",
        "            validate_input_data(df)\n",
        "            freq = detect_frequency(df, date_col)\n",
        "            seasonality = detect_seasonality(df, value_col, freq)\n",
        "\n",
        "            # Model selection\n",
        "            models = {{\n",
        "                'Prophet': lambda: forecast_with_prophet_enhanced(df, value_col, date_col, forecast_horizon, seasonality),\n",
        "                'SARIMAX': lambda: forecast_with_sarimax(df, value_col, seasonal_order=(1,1,1,seasonality[0] if seasonality else 12))\n",
        "            }}\n",
        "\n",
        "            # Evaluate models\n",
        "            best_model = None\n",
        "            best_score = float('inf')\n",
        "            tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "            for name, model_fn in models.items():\n",
        "                try:\n",
        "                    scores = []\n",
        "                    for train_idx, test_idx in tscv.split(df):\n",
        "                        train, test = df.iloc[train_idx], df.iloc[test_idx]\n",
        "                        result = evaluate_model(model_fn, train, test, value_col, train[value_col])\n",
        "                        scores.append(result['mase'])\n",
        "\n",
        "                    avg_score = np.mean(scores)\n",
        "                    if avg_score < best_score:\n",
        "                        best_score = avg_score\n",
        "                        best_model = name\n",
        "                except Exception as e:\n",
        "                    print(f\"Model {{name}} failed: {{str(e)}}\")\n",
        "\n",
        "            # Generate final forecast\n",
        "            forecast = models[best_model]()\n",
        "            return forecast\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Forecasting failed: {{str(e)}}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    # ================================\n",
        "    # Final Implementation\n",
        "    # ================================\n",
        "    df = pd.DataFrame(data)\n",
        "    date_col, value_col, id_col = detect_columns(df)\n",
        "    forecast_horizon = determine_forecast_horizon(df, date_col)\n",
        "    forecast_df = generate_forecast(df, date_col, value_col, id_col, forecast_horizon)\n",
        "\n",
        "    return forecast_df\n",
        "\n",
        "\n",
        "# ERRORS TO AVOID:\n",
        "\n",
        " **Try to prevent these errors**:\n",
        "\n",
        " - ValueError: If using all scalar values, you must pass an index\n",
        "\n",
        " - KeyErrors – This is typically because the columns are not selected properly from the incoming data. Ensure there is a single id_col, date_col, and value_col in the data.\n",
        "\n",
        " - NameError: name 'extend_single_timeseries_frame' is not defined – This happens when one of the functions was not included\n",
        "\n",
        " - AttributeError: 'dict' object has no attribute 'unique' – This happens when the a dictionary wasn't converted to a pandas DataFrame\n",
        "\n",
        " # RETURN\n",
        "  - Return Python code wrapped in ```python```\n",
        "\n",
        " # INPUTS\n",
        "  - Data sample: {data}\n",
        "  - User's Forecast Question: {question}\n",
        "\"\"\",\n",
        "    input_variables=[\"question\", \"data\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IABB4oK63ruZ"
      },
      "source": [
        "### Making a Custom output structure for python code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pm7Buv1lzHLX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "class PythonOutputParser(BaseOutputParser[str]):\n",
        "    \"\"\"Parse the output of an LLM call to a Python code block.\"\"\"\n",
        "\n",
        "    def parse(self, text: str) -> str:\n",
        "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
        "        # Find the first occurrence of a Python code block\n",
        "        match = re.search(r\"```python\\n(.*?)\\n```\", text, re.DOTALL)\n",
        "\n",
        "        if match:\n",
        "            # Extract the content within the code block\n",
        "            python_code = match.group(1).strip()\n",
        "            return python_code\n",
        "        else:\n",
        "            # If no code block is found, return the original text or an empty string\n",
        "            return text.strip() # Or return \"\" depending on desired behavior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIGkutnuzgRE"
      },
      "outputs": [],
      "source": [
        "forecast_generator=forecast_code_prompt | llm | PythonOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1N9L2XbzsmM"
      },
      "outputs": [],
      "source": [
        "result2=forecast_generator.invoke({\"question\": \"I have price data and I want to see the total price aggregated by month.\", \"data\":df.head(1000).to_dict()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KFGd8Ecm2zLd",
        "outputId": "6983020c-8604-4166-c770-38413f1f3213"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python \ndef forecast_ts(data):\n    import numpy as np\n    import pandas as pd\n    import warnings\n    warnings.filterwarnings('ignore')\n    from statsmodels.tsa.statespace.sarimax import SARIMAX\n    from prophet import Prophet\n    from sklearn.metrics import mean_absolute_error\n    from sklearn.model_selection import TimeSeriesSplit\n\n    # 1. DATA INGESTION AND DATETIME CONVERSION\n    df = pd.DataFrame(data)\n    # Identify date and value columns\n    date_col_candidates = [col for col in df.columns if 'date' in col.lower()]\n    date_col = date_col_candidates[0] if len(date_col_candidates) > 0 else df.columns[0]\n    value_col_candidates = [col for col in df.columns if col != date_col]\n    value_col = value_col_candidates[0] if len(value_col_candidates) > 0 else 'value'\n    if value_col == 'value':\n        df.rename(columns={df.columns[1]: value_col}, inplace=True)\n    df[date_col] = pd.to_datetime(df[date_col])\n    df = df[[date_col, value_col]]\n\n    # Add \"i\" as ID if needed\n    df['i'] = 0\n\n    # Remove rows where nothing is present for the value column\n    df = df[df[value_col].notna()]\n\n    # 2. AGGREGATE TO MONTHLY TOTALS\n    df['month'] = df[date_col].dt.to_period('M').dt.to_timestamp()\n    agg_df = df.groupby(['i','month'])[value_col].sum().reset_index()\n    agg_df.rename(columns={'month': 'date'}, inplace=True)\n\n    # 3. RESAMPLE TO REGULAR MONTHLY INDEX (Prophet and SARIMAX prefer regular spacing)\n    min_month = agg_df['date'].min()\n    max_month = agg_df['date'].max()\n    monthly_idx = pd.date_range(min_month, max_month, freq='MS')\n    merged_df = pd.DataFrame({'date': monthly_idx})\n    merged_df = merged_df.merge(agg_df[['date', value_col]], on='date', how='left')\n    merged_df['i'] = 0\n\n    # 4. DETERMINE FORECAST HORIZON (12 months ahead for monthly data)\n    forecast_horizon = 12\n\n    # 5. ADVANCED STATIONARITY TESTING AND IMPUTATION\n    series = merged_df[value_col]\n    # Simple imputation (linear interpolation). Better can be used if needed.\n    series = series.interpolate(method='linear', limit_direction='both')\n    merged_df[value_col] = series\n\n    # Function to calculate MASE\n    def mase(y_true, y_pred, y_train):\n        naive = np.mean(np.abs(np.diff(y_train)))\n        if naive == 0:  # fallback\n            naive = 1\n        return mean_absolute_error(y_true, y_pred) / naive\n\n    # Prepare for model split\n    y = merged_df[value_col]\n    dates = merged_df['date']\n    tscv = TimeSeriesSplit(n_splits=3)\n    results = {}\n    y_train_full = y.values\n\n    # 6. SARIMAX model\n    def fit_predict_sarimax(train, test_len):\n        # Enforce stationarity (log1p if needed)\n        train_y = train.copy()\n        order = (1,1,1)\n        seasonal_order = (1,1,0,12)  # monthly seasonality\n        try:\n            model = SARIMAX(train_y, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n            model_fit = model.fit(disp=False)\n            pred = model_fit.forecast(steps=test_len)\n            pred_ci = model_fit.get_forecast(steps=test_len).conf_int(alpha=0.05)\n            lower = pred_ci.iloc[:, 0]\n            upper = pred_ci.iloc[:, 1]\n            return pred.values, lower.values, upper.values\n        except Exception:\n            # fallback: flat forecast\n            mean_val = np.mean(train_y)\n            pred = np.full(test_len, mean_val)\n            return pred, np.full(test_len, mean_val), np.full(test_len, mean_val)\n\n    # 7. Prophet model\n    def fit_predict_prophet(train_df, periods):\n        model_df = pd.DataFrame({'ds': train_df['date'], 'y': train_df[value_col]})\n        m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False, interval_width=0.95)\n        m.fit(model_df)\n        future = m.make_future_dataframe(periods=periods, freq='MS')\n        forecast = m.predict(future)\n        yhat = forecast['yhat'][-periods:].values\n        lower = forecast['yhat_lower'][-periods:].values\n        upper = forecast['yhat_upper'][-periods:].values\n        return yhat, lower, upper\n\n    # 8. Time series cross-validation for model selection\n    maes = {'SARIMAX': [], 'Prophet': []}\n    mases = {'SARIMAX': [], 'Prophet': []}\n    # Since we have a single time series, we can do simple splits on the regularized monthly data\n    n_splits = 3\n    split_size = int(merged_df.shape[0] / (n_splits + 1))\n    for i in range(n_splits):\n        train_end = split_size * (i + 1)\n        train = merged_df[value_col].iloc[:train_end]\n        test = merged_df[value_col].iloc[train_end:train_end + split_size]\n        train_dates = merged_df['date'].iloc[:train_end]\n        test_dates = merged_df['date'].iloc[train_end:train_end + split_size]\n\n        # SARIMAX\n        try:\n            pred_sarimax, _, _ = fit_predict_sarimax(train, len(test))\n            maes['SARIMAX'].append(mean_absolute_error(test, pred_sarimax))\n            mases['SARIMAX'].append(mase(test, pred_sarimax, train))\n        except:\n            continue\n\n        # Prophet\n        try:\n            train_df_prophet = pd.DataFrame({'date': train_dates, value_col: train})\n            pred_prophet, _, _ = fit_predict_prophet(train_df_prophet, len(test))\n            maes['Prophet'].append(mean_absolute_error(test, pred_prophet))\n            mases['Prophet'].append(mase(test, pred_prophet, train))\n        except:\n            continue\n\n    avg_mase = {m: np.mean(v) for m, v in mases.items() if len(v) > 0}\n    # Select the best model (lowest MASE)\n    if not avg_mase:\n        # fallback\n        best_model = 'SARIMAX'\n    else:\n        best_model = min(avg_mase, key=avg_mase.get)\n\n    # 9. FINAL FORECAST\n    # Training data is all of merged_df\n    if best_model == 'Prophet':\n        model_df = pd.DataFrame({'date': merged_df['date'], value_col: merged_df[value_col]})\n        yhat, lower, upper = fit_predict_prophet(model_df, forecast_horizon)\n    else:\n        train = merged_df[value_col]\n        yhat, lower, upper = fit_predict_sarimax(train, forecast_horizon)\n\n    # 10. BUILD FORECAST DATAFRAME\n    future_dates = pd.date_range(merged_df['date'].max() + pd.offsets.MonthBegin(1), periods=forecast_horizon, freq='MS')\n    forecast_df = pd.DataFrame({\n        'i': 0,\n        'date': future_dates,\n        'forecast': yhat,\n        'forecast_lower': lower,\n        'forecast_upper': upper\n    })\n\n    # Attach columns in correct order\n    forecast_df = forecast_df[['i', 'date', 'forecast', 'forecast_lower', 'forecast_upper']]\n\n    return forecast_df\n```"
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "Markdown(f\"```python \\n{result2}\\n```\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B13nextnTcQB"
      },
      "source": [
        "# 3- Data Analyst agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjGvx_zTTcBk"
      },
      "outputs": [],
      "source": [
        "data_questions_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a Data Analysis Expert specialized in time series forecasting. Your task is to:\n",
        "1. Analyze the user's question about forecasting data\n",
        "2. Generate Python code to answer the question using the provided data\n",
        "3. Return clean, executable Python code that produces the requested analysis\n",
        "\n",
        "# GUIDELINES:\n",
        "- Always work with the provided data (don't create synthetic data)\n",
        "- Include all necessary imports within the function\n",
        "- Handle missing/incorrect data gracefully\n",
        "- Return a pandas DataFrame with the results\n",
        "- Make the code reusable and well-commented\n",
        "\n",
        "# COMMON QUESTION TYPES TO HANDLE:\n",
        "1. Data Exploration:\n",
        "   - Summary statistics\n",
        "   - Missing value analysis\n",
        "   - Time period coverage\n",
        "   - Outlier detection\n",
        "\n",
        "2. Forecasting Preparation:\n",
        "   - Resampling time series\n",
        "   - Handling missing dates\n",
        "   - Feature engineering\n",
        "   - Stationarity tests\n",
        "\n",
        "3. Forecast Analysis:\n",
        "   - Model comparisons\n",
        "   - Error metrics\n",
        "   - Confidence intervals\n",
        "   - Residual analysis\n",
        "\n",
        "4. Data Transformations:\n",
        "   - Normalization/scaling\n",
        "   - Differencing\n",
        "   - Log transformations\n",
        "   - Rolling statistics\n",
        "\n",
        "# OUTPUT FORMAT:\n",
        "```python\n",
        "def analyze_forecast_data(data):\n",
        "    \\\"\\\"\\\"\n",
        "    Analyzes forecasting data based on user question.\n",
        "\n",
        "    Args:\n",
        "        data: Input data as dictionary (will be converted to DataFrame)\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame with analysis results\n",
        "    \\\"\\\"\\\"\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from statsmodels.tsa.stattools import adfuller\n",
        "    # Other necessary imports...\n",
        "\n",
        "    # Convert input to DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # [Your analysis code here]\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# EXAMPLE QUESTIONS:\n",
        "\"What's the monthly average of the time series?\"\n",
        "\n",
        "\"Are there any missing dates in the time series?\"\n",
        "\n",
        "\"Show me the rolling 7-day average\"\n",
        "\n",
        "\"Is the time series stationary?\"\n",
        "\n",
        "\"What's the autocorrelation structure?\"\n",
        "\n",
        "CURRENT QUESTION:\n",
        "{question}\n",
        "\n",
        "DATA SAMPLE (first 5 rows):\n",
        "{data_head}\n",
        "\n",
        "COLUMNS IN DATA:\n",
        "{columns}\n",
        "\n",
        "# IMPORTANT:\n",
        "Wrap your code in python delimiters\n",
        "\n",
        "The function must be named analyze_forecast_data\n",
        "\n",
        "Return a DataFrame even for single-value results\n",
        "\"\"\",\n",
        "input_variables=[\"question\", \"data_head\", \"columns\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvYLagq6WXI2"
      },
      "outputs": [],
      "source": [
        "data_questions_agent = data_questions_prompt | llm | PythonOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khgW8VPJ-y_B"
      },
      "source": [
        "# Visulization Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McSyO3VG-WJw"
      },
      "source": [
        "## Using LLM to detect columns to plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HliBWVtPKYJp"
      },
      "outputs": [],
      "source": [
        "column_detection_prompt = PromptTemplate(\n",
        "    template=\"\"\"Analyze the following DataFrame columns and identify:\n",
        "    1. The datetime column (most likely to contain dates/times)\n",
        "    2. The value column (numeric column to be visualized)\n",
        "\n",
        "    Return JSON with:\n",
        "    - \"date_column\": name of the datetime column\n",
        "    - \"value_column\": name of the numeric value column\n",
        "\n",
        "    Available columns: {columns}\n",
        "    First row sample: {first_row}\n",
        "\n",
        "    Focus on these common patterns:\n",
        "    - Date columns often have names like: date, time, timestamp, datetime\n",
        "    - Value columns are typically numeric and have names like: value, sales, price, quantity\n",
        "\n",
        "    If uncertain, choose the most likely candidates.\"\"\",\n",
        "    input_variables=[\"columns\", \"first_row\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C44fOHQKbII"
      },
      "outputs": [],
      "source": [
        "column_detection_chain = column_detection_prompt | llm | JsonOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_4i4jlVKc7M"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "from plotly import graph_objects as go\n",
        "\n",
        "def detect_columns(df: pd.DataFrame) -> Dict[str, str]:\n",
        "    \"\"\"Use LLM to detect date and value columns\"\"\"\n",
        "    columns = list(df.columns)\n",
        "    first_row = df.iloc[0].to_dict()\n",
        "\n",
        "    try:\n",
        "        result = column_detection_chain.invoke({\n",
        "            \"columns\": columns,\n",
        "            \"first_row\": first_row\n",
        "        })\n",
        "        return {\n",
        "            \"date_column\": result[\"date_column\"],\n",
        "            \"value_column\": result[\"value_column\"]\n",
        "        }\n",
        "    except:\n",
        "        # Fallback to automatic detection\n",
        "        date_col = None\n",
        "        value_col = None\n",
        "\n",
        "        # Find first datetime column\n",
        "        for col in df.columns:\n",
        "            if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
        "                date_col = col\n",
        "                break\n",
        "            try:\n",
        "                pd.to_datetime(df[col])\n",
        "                date_col = col\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Find first numeric column\n",
        "        numeric_cols = df.select_dtypes(include='number').columns\n",
        "        value_col = numeric_cols[0] if len(numeric_cols) > 0 else None\n",
        "\n",
        "        return {\n",
        "            \"date_column\": date_col,\n",
        "            \"value_column\": value_col\n",
        "        }\n",
        "\n",
        "def create_visualization(state: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Creates an interactive Plotly line plot for the forecast.\n",
        "    Automatically detects date and value columns using LLM.\n",
        "    \"\"\"\n",
        "    print(\"Generating Interactive Forecast Visualization\")\n",
        "\n",
        "    # Convert data from state\n",
        "    forecast_df = pd.DataFrame(state['data_forecast'])\n",
        "\n",
        "    # Detect columns in forecast data\n",
        "    forecast_cols = detect_columns(forecast_df)\n",
        "    date_col = forecast_cols[\"date_column\"]\n",
        "    value_col = forecast_cols[\"value_column\"]\n",
        "\n",
        "    if not date_col or not value_col:\n",
        "        raise ValueError(\"Could not detect required columns (date and value)\")\n",
        "\n",
        "    # Process date columns\n",
        "    forecast_df[date_col] = pd.to_datetime(forecast_df[date_col])\n",
        "\n",
        "    # Create Plotly figure\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add forecast trace\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=forecast_df[date_col],\n",
        "            y=forecast_df[value_col],\n",
        "            mode='lines',\n",
        "            name='Forecast',\n",
        "            line=dict(color='#ff7f0e', width=2),\n",
        "            hovertemplate='%{x|%Y-%m-%d}<br>%{y:.2f}<extra></extra>'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Add layout configuration\n",
        "    fig.update_layout(\n",
        "        title='Time Series Forecast',\n",
        "        xaxis_title=date_col,\n",
        "        yaxis_title=value_col,\n",
        "        hovermode='x unified',\n",
        "        plot_bgcolor='white',\n",
        "        margin=dict(l=20, r=20, t=60, b=20),\n",
        "        legend=dict(\n",
        "            orientation='h',\n",
        "            yanchor='bottom',\n",
        "            y=1.02,\n",
        "            xanchor='right',\n",
        "            x=1\n",
        "        ),\n",
        "        xaxis=dict(\n",
        "            showgrid=True,\n",
        "            gridcolor='lightgray',\n",
        "            gridwidth=1,\n",
        "            tickformat='%Y-%m-%d'\n",
        "        ),\n",
        "        yaxis=dict(\n",
        "            showgrid=True,\n",
        "            gridcolor='lightgray',\n",
        "            gridwidth=1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Store both the figure object and its data\n",
        "    return {\n",
        "        **state,\n",
        "        \"visualization\": {\n",
        "            \"figure_data\": {\n",
        "                \"dates\": forecast_df[date_col].dt.strftime('%Y-%m-%d').tolist(),\n",
        "                \"values\": forecast_df[value_col].tolist(),\n",
        "                \"date_col\": date_col,\n",
        "                \"value_col\": value_col\n",
        "            },\n",
        "            \"plotly_figure\": fig\n",
        "        },\n",
        "        \"plotly_figure\": fig,\n",
        "        \"date_column\": date_col,\n",
        "        \"value_column\": value_col\n",
        "    }\n",
        "\n",
        "def display_visualization(state: Dict) -> Dict:\n",
        "    \"\"\"Displays the Plotly figure and returns unmodified state\"\"\"\n",
        "    fig = state.get('plotly_figure')\n",
        "    if fig:\n",
        "        display(fig)\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPJbgDWd33uE"
      },
      "source": [
        "# Using Langraph to connect the workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVDH--Em4ALS"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import Dict, Optional\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    user_question: str\n",
        "    data_sample_sql: dict\n",
        "    data_sql: dict\n",
        "    forecast_code: str\n",
        "    data_sample_forecast: dict\n",
        "    data_forecast: dict\n",
        "    visualization: Optional[Dict[str, Dict[str, list] | go.Figure]]\n",
        "    plotly_figure: Optional[go.Figure]\n",
        "    date_column: Optional[str]\n",
        "    value_column: Optional[str]\n",
        "    is_data_question: bool\n",
        "    routing_reason: Optional[str]\n",
        "    data_analysis_code: Optional[str]\n",
        "    data_analysis_results: Optional[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m40t0UTR4ra6"
      },
      "outputs": [],
      "source": [
        "def preprocess_question(state: GraphState) -> GraphState:\n",
        "    question = state['user_question']\n",
        "\n",
        "    # Get classification from LLM\n",
        "    try:\n",
        "        classification = forecast_preprocessor.invoke({\"question\": question})\n",
        "        is_data_question = classification[\"question_type\"] == \"DATA_ANALYSIS\"\n",
        "\n",
        "        # If forecast question, get formatted version\n",
        "        if not is_data_question:\n",
        "            response = forecast_preprocessor.invoke({\"question\": question})\n",
        "            return {\n",
        "                **state,\n",
        "                \"is_data_question\": False,\n",
        "                \"routing_reason\": classification[\"reasoning\"]\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                **state,\n",
        "                \"is_data_question\": True,\n",
        "                \"routing_reason\": classification[\"reasoning\"]\n",
        "            }\n",
        "\n",
        "    except Exception as e:\n",
        "        # Fallback to original behavior if routing fails\n",
        "        print(f\"Routing failed: {str(e)}\")\n",
        "        response = forecast_preprocessor.invoke({\"question\": question})\n",
        "        return {\n",
        "            **state,\n",
        "            \"is_data_question\": False,\n",
        "            \"routing_reason\": \"Fallback: Defaulted to forecast\"\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGEEeVVPc2Uq"
      },
      "outputs": [],
      "source": [
        "def handle_data_question(state: GraphState) -> GraphState:\n",
        "    if not state.get('is_data_question'):\n",
        "        return state\n",
        "\n",
        "    print(\"Handling data question...\")\n",
        "    question = state['user_question']\n",
        "    data_sample = state['data_sample_sql']\n",
        "    columns = list(pd.DataFrame(data_sample).columns)\n",
        "\n",
        "    try:\n",
        "        code = data_questions_agent.invoke({\n",
        "            \"question\": question,\n",
        "            \"data_head\": data_sample,\n",
        "            \"columns\": columns\n",
        "        })\n",
        "\n",
        "        local_vars = {}\n",
        "        global_vars = {}\n",
        "        exec(code, global_vars, local_vars)\n",
        "        analysis_fn = local_vars['analyze_forecast_data']\n",
        "        results_df = analysis_fn(state['data_sql'])\n",
        "\n",
        "        return {\n",
        "            **state,\n",
        "            \"data_analysis_code\": code,\n",
        "            \"data_analysis_results\": results_df.to_dict()\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {**state, \"error\": str(e)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsXolMbdVHBN"
      },
      "outputs": [],
      "source": [
        "def generate_forecast_code(state):\n",
        "  print('Forecaster Generating')\n",
        "  question=state['user_question']\n",
        "  data=state.get('data_sample_sql')\n",
        "  response=forecast_generator.invoke({\"question\": question, \"data\": data})\n",
        "  return{\n",
        "      \"forecast_code\": response\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrjhZkL0-n0p"
      },
      "source": [
        "# Executing Forecast Python Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9ceeu3tS_q5"
      },
      "outputs": [],
      "source": [
        "def execute_forecast_code(state):\n",
        "    print('Forecaster Executing')\n",
        "    # Retrieve the generated Python code and the data from the state\n",
        "    code = state.get('forecast_code')\n",
        "    # Get the full data as a dictionary\n",
        "    data_dict = state.get('data_sql')\n",
        "    # Get the user's original question\n",
        "    user_question = state.get('user_question')\n",
        "\n",
        "    # Prepare dictionaries for executing the code in an isolated environment\n",
        "    local_vars = {}\n",
        "    global_vars = {}\n",
        "\n",
        "    # Execute the generated code. This will define the 'analyze_data' function.\n",
        "    exec(code, global_vars, local_vars)\n",
        "\n",
        "    # Call the newly defined 'analyze_data' function with the data and question\n",
        "    # The function is accessed from the local_vars dictionary\n",
        "    analysis_result_df = local_vars['forecast_ts'](data_dict)\n",
        "\n",
        "    # Return the results, including a sample and the full data, converted back to dictionaries\n",
        "    return {\n",
        "        \"data_sample_forecast\": analysis_result_df.head(1000).to_dict(),\n",
        "        \"data_forecast\": analysis_result_df.to_dict()\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hVmIdEf-idD"
      },
      "source": [
        "## Defining the workflow structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVzoahsdUD0J",
        "outputId": "3be998ad-4c67-4f16-e9bf-9e9d06dce153"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7926ccff5210>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "workflow.add_node(\"preprocess_forecast\", preprocess_question)\n",
        "workflow.add_node(\"generate_forecast_code\", generate_forecast_code)\n",
        "workflow.add_node(\"execute_forecast_code\", execute_forecast_code)\n",
        "workflow.add_node(\"create_visualization\", create_visualization)\n",
        "workflow.add_node(\"display_visualization\", display_visualization)\n",
        "workflow.add_node(\"handle_data_question\", handle_data_question)\n",
        "\n",
        "def route_question(state: GraphState) -> str:\n",
        "    if state.get('is_data_question'):\n",
        "        return \"to_data_question\"\n",
        "    return \"to_forecast\"\n",
        "\n",
        "workflow.set_entry_point('preprocess_forecast')\n",
        "workflow.add_conditional_edges(\n",
        "    \"preprocess_forecast\",\n",
        "    route_question,\n",
        "    {\n",
        "        \"to_data_question\": \"handle_data_question\",\n",
        "        \"to_forecast\": \"generate_forecast_code\"\n",
        "    }\n",
        ")\n",
        "workflow.add_edge('preprocess_forecast', 'generate_forecast_code')\n",
        "workflow.add_edge('generate_forecast_code', 'execute_forecast_code')\n",
        "workflow.add_edge('execute_forecast_code', 'create_visualization')\n",
        "workflow.add_edge('create_visualization', 'display_visualization')\n",
        "workflow.add_edge('display_visualization', END)\n",
        "workflow.add_edge(\"handle_data_question\", END)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt64uqDIXKgN"
      },
      "outputs": [],
      "source": [
        "app=workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "f1bDAyL9-8BE",
        "outputId": "18b8ed08-2847-4d34-a5e6-c618dd92dfb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "Image(app.get_graph().draw_mermaid_png())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv353L2jBBbv"
      },
      "source": [
        "# Main Use Case function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEquMsIMXubG"
      },
      "outputs": [],
      "source": [
        "def analyze_and_show(question: str, data: pd.DataFrame, sample_size: int = 100) -> None:\n",
        "    \"\"\"\n",
        "    Runs the full workflow and displays:\n",
        "    - For data questions: Prints analysis results\n",
        "    - For forecast questions: Prints forecast DataFrame and shows visualization\n",
        "    \"\"\"\n",
        "    # Prepare input data\n",
        "    if len(data) > sample_size:\n",
        "        sample = data.sample(sample_size)\n",
        "    else:\n",
        "        sample = data.copy()\n",
        "\n",
        "    # Run the workflow\n",
        "    result = app.invoke({\n",
        "        \"user_question\": question,\n",
        "        \"data_sample_sql\": sample.to_dict(),\n",
        "        \"data_sql\": data.to_dict()\n",
        "    })\n",
        "\n",
        "    # Display appropriate results based on question type\n",
        "    if result.get('is_data_question'):\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"DATA ANALYSIS RESULTS: {question}\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Classification Reason: {result.get('routing_reason', 'Unknown')}\")\n",
        "        print(\"\\nAnalysis Code Generated:\")\n",
        "        print(\"-\"*50)\n",
        "        print(result.get('data_analysis_code', 'No code generated'))\n",
        "\n",
        "        print(\"\\nAnalysis Results:\")\n",
        "        print(\"-\"*50)\n",
        "        analysis_df = pd.DataFrame(result.get('data_analysis_results', {}))\n",
        "        display(analysis_df)\n",
        "\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"FORECAST RESULTS: {question}\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Classification Reason: {result.get('routing_reason', 'Unknown')}\")\n",
        "        print(\"\\nGenerated Forecast Code:\")\n",
        "        print(\"-\"*50)\n",
        "        print(result.get('forecast_code', 'No code generated'))\n",
        "\n",
        "        print(\"\\nForecast DataFrame:\")\n",
        "        print(\"-\"*50)\n",
        "        forecast_df = pd.DataFrame(result.get('data_forecast', {}))\n",
        "        display(forecast_df)\n",
        "\n",
        "        # Show visualization if available\n",
        "        if result.get('plotly_figure'):\n",
        "            print(\"\\nForecast Visualization:\")\n",
        "            print(\"-\"*50)\n",
        "            display(result['plotly_figure'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgsC_TUiA8xp"
      },
      "source": [
        "## Some use cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "KX8kpeiF7Vq5",
        "outputId": "dd407893-20fb-4ef3-8386-644fecb09f30"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-37-1794004120.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# analyze_and_show(\"Forecast prices for next 30 days\", df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# analyze_and_show(\"Predict sales for next quarter\", df2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0manalyze_and_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What will the oil price be in the next 6 months?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# # Edge Cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-35-4131314929.py\u001b[0m in \u001b[0;36manalyze_and_show\u001b[0;34m(question, data, sample_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Run the workflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     result = app.invoke({\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;34m\"user_question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m\"data_sample_sql\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2717\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2719\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2720\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2721\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2435\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2437\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    162\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-28-2102123054.py\u001b[0m in \u001b[0;36mpreprocess_question\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Get classification from LLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecast_preprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mis_data_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"DATA_ANALYSIS\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m         return cast(\n\u001b[1;32m    330\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    893\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 results.append(\n\u001b[0;32m--> 719\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    720\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    961\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_llm7/chat_llm7.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0minput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokeniser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         response = requests.post(\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# analyze_and_show(\"What are the summary statistics?\", df)\n",
        "# analyze_and_show(\"Is this time series stationary?\", df)\n",
        "# analyze_and_show(\"Show me the 7-day rolling average\", df)\n",
        "\n",
        "# # Forecast Examples\n",
        "# analyze_and_show(\"Forecast prices for next 30 days\", df)\n",
        "# analyze_and_show(\"Predict sales for next quarter\", df2)\n",
        "analyze_and_show(\"What will the oil price be in the next 6 months?\", df)\n",
        "\n",
        "# # Edge Cases\n",
        "# analyze_and_show(\"Analyze missing values and forecast next week\", df)  # Will default to forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmaWhWH_Eq6i",
        "outputId": "654c9e5a-bba4-436c-bb72-790304618a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.46.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.43.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.46.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.46.0 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streamlit Web App"
      ],
      "metadata": {
        "id": "Jwjk_Y0rEft_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwLYHANuEswc",
        "outputId": "b84e984b-2726-4ef7-8b37-f4c08be6b66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "\n",
        "from langchain_llm7 import ChatLLM7\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser,BaseOutputParser\n",
        "from langgraph.graph import StateGraph,END\n",
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "\n",
        "llm = ChatLLM7(\n",
        "    model='gpt-4o-mini'\n",
        ")\n",
        "\n",
        "## 1- Forecast Preprocessor\n",
        "\n",
        "forecast_preprocessor_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are an expert question classifier for time series analysis. Your task is to:\n",
        "\n",
        "1. Analyze the user's question\n",
        "2. Determine if it requires:\n",
        "   - Data analysis/exploration (statistics, diagnostics, preparation)\n",
        "   - Time series forecasting (future predictions)\n",
        "3. Return JSON with your classification\n",
        "\n",
        "# CLASSIFICATION CRITERIA:\n",
        "- DATA ANALYSIS QUESTIONS:\n",
        "  - Requests for statistics, summaries, or data properties\n",
        "  - Questions about data quality (missing values, outliers)\n",
        "  - Time series diagnostics (stationarity, autocorrelation)\n",
        "  - Data transformations (rolling stats, differencing)\n",
        "\n",
        "- FORECASTING QUESTIONS:\n",
        "  - Requests for future predictions\n",
        "  - Questions about future trends\n",
        "  - Any question containing time horizons (next 30 days, etc.)\n",
        "\n",
        "# EXAMPLES:\n",
        "1. \"Show me monthly averages\" → DATA_ANALYSIS\n",
        "2. \"Forecast prices for next year\" → FORECAST\n",
        "3. \"Is this series stationary?\" → DATA_ANALYSIS\n",
        "4. \"Predict sales for Q4\" → FORECAST\n",
        "\n",
        "# OUTPUT FORMAT:\n",
        "{{\n",
        "    \"question_type\": \"DATA_ANALYSIS\" or \"FORECAST\",\n",
        "    \"reasoning\": \"brief explanation of your classification\"\n",
        "}}\n",
        "\n",
        "USER QUESTION: {question}\n",
        "\"\"\",\n",
        "    input_variables=[\"question\"]\n",
        ")\n",
        "\n",
        "\n",
        "forecast_preprocessor=forecast_preprocessor_prompt | llm | JsonOutputParser()\n",
        "\n",
        "## 2- Forecast Code Generator\n",
        "\n",
        "forecast_code_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a forecasting expert. Given an input question and data provided as a dictionary from a SQL agent, your job is to write Python code to perform a forecast using the data as an input and determining a forecast horizon and which items to forecast.\n",
        "\n",
        "Return Python code in this format:\n",
        "\n",
        "```python\n",
        "def forecast_ts(data):\n",
        "    ...\n",
        "    return forecast_df\n",
        "\n",
        "\n",
        "# **IMPORTANT NOTES**:\n",
        "\n",
        " - Return a single function named forecast_ts that ingests a parameter containing \"data\", and outputs one data frame (forecast_df).\n",
        "\n",
        " - Do NOT re-write data inside the generated Python code.\n",
        "\n",
        " - Make sure to convert columns containing date information to Pandas datetime.\n",
        "\n",
        " - If no ID column is provided, make an ID column for use with the forecasts. Just use \"i\" for the ID.\n",
        "\n",
        "# **KEY DECISIONS FROM THE PROVIDED QUESTION**:\n",
        " - Which item should be forecasted? If none is provided, assume that all items should be forecasted (use a loop to do this).\n",
        "\n",
        " - How far into the future should the forecast be made?\n",
        "\n",
        " - If no forecast horizon is provided, determine a reasonable forecast horizon based on the data provided and its periodicity (example: if monthly data, forecast 12 months—a year's worth).\n",
        "\n",
        " - If more than one ID column is included in the data, consolidate into a single \"id_column\"\n",
        "\n",
        "# **ENHANCED DATA PROCESSING FUNCTIONS**\n",
        "\n",
        "def forecast_ts(data):\n",
        "    # ================================\n",
        "    # Wrap imports inside function\n",
        "    # ================================\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from xgboost import XGBRegressor\n",
        "    from statsmodels.tsa.arima.model import ARIMA\n",
        "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "    from sklearn.model_selection import TimeSeriesSplit\n",
        "    from prophet import Prophet\n",
        "    from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "    from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "    from tbats import TBATS\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    # ================================\n",
        "    # Enhanced Data Validation\n",
        "    # ================================\n",
        "    def validate_input_data(df):\n",
        "        \"\"Comprehensive data validation with detailed error messages\"\"\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            raise ValueError(\"Input must be a pandas DataFrame\")\n",
        "\n",
        "        if len(df) < 12:\n",
        "            raise ValueError(\"Insufficient data points (minimum 12 required)\")\n",
        "\n",
        "        if df.empty:\n",
        "            raise ValueError(\"Empty DataFrame provided\")\n",
        "\n",
        "        if df.isna().all().any():\n",
        "            raise ValueError(\"Column with all NaN values detected\")\n",
        "\n",
        "        if df.duplicated().any():\n",
        "            print(\"Warning: Duplicate rows detected in input data\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    # ================================\n",
        "    # Robust Column Detection\n",
        "    # ================================\n",
        "    def detect_columns(df):\n",
        "        \"\"Advanced column detection with multiple fallback strategies\"\"\n",
        "        date_col = None\n",
        "        value_col = None\n",
        "        id_col = 'i'  # Default ID column\n",
        "\n",
        "        # Common naming patterns for date and value columns\n",
        "        date_patterns = ['date', 'time', 'timestamp', 'datetime', 'ds', 'dt']\n",
        "        value_patterns = ['value', 'sales', 'price', 'quantity', 'amount', 'target']\n",
        "        id_patterns = ['id', 'item', 'product', 'store', 'sku']\n",
        "\n",
        "        # Try exact matches first\n",
        "        for col in df.columns:\n",
        "            col_lower = col.lower()\n",
        "            if date_col is None and any(p in col_lower for p in date_patterns):\n",
        "                date_col = col\n",
        "            if value_col is None and any(p in col_lower for p in value_patterns):\n",
        "                value_col = col\n",
        "            if any(p in col_lower for p in id_patterns):\n",
        "                id_col = col\n",
        "\n",
        "        # Try type inference if not found by name\n",
        "        if date_col is None:\n",
        "            for col in df.columns:\n",
        "                try:\n",
        "                    if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
        "                        date_col = col\n",
        "                        break\n",
        "                    pd.to_datetime(df[col])  # Test conversion\n",
        "                    date_col = col\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        if value_col is None:\n",
        "            numeric_cols = df.select_dtypes(include='number').columns\n",
        "            if len(numeric_cols) > 0:\n",
        "                value_col = numeric_cols[0]\n",
        "\n",
        "        # Final validation\n",
        "        if date_col is None:\n",
        "            raise ValueError(\n",
        "                \"Could not identify date column. Available columns: \"\n",
        "                f\"{{list(df.columns)}}\"\n",
        "            )\n",
        "        if value_col is None:\n",
        "            raise ValueError(\n",
        "                \"Could not identify value column. Available numeric columns: \"\n",
        "                f\"{{list(df.select_dtypes(include='number').columns)}}\"\n",
        "            )\n",
        "\n",
        "        return date_col, value_col, id_col\n",
        "\n",
        "    # ================================\n",
        "    # Data Cleaning and Preparation\n",
        "    # ================================\n",
        "    def prepare_data(df, date_col, value_col):\n",
        "        \"\"Comprehensive data cleaning and preparation\"\"\n",
        "        # Convert date column\n",
        "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
        "\n",
        "        # Handle missing dates\n",
        "        if df[date_col].isna().any():\n",
        "            print(\"Warning: Some dates could not be parsed. Dropping invalid rows.\")\n",
        "            df = df.dropna(subset=[date_col])\n",
        "\n",
        "        # Sort by date\n",
        "        df = df.sort_values(date_col)\n",
        "\n",
        "        # Handle missing values in value column\n",
        "        if df[value_col].isna().any():\n",
        "            print(\"Warning: Missing values found in target column. Using forward fill.\")\n",
        "            df[value_col] = df[value_col].ffill()\n",
        "\n",
        "\n",
        "        return df\n",
        "\n",
        "    # ================================\n",
        "    # Advanced Frequency Detection\n",
        "    # ================================\n",
        "    def detect_frequency(df, date_col):\n",
        "        \"\"Robust frequency detection with multiple fallback methods\"\"\n",
        "        try:\n",
        "            # Try pandas inference first\n",
        "            freq = pd.infer_freq(df[date_col])\n",
        "            if freq:\n",
        "                return freq\n",
        "\n",
        "            # Calculate time differences\n",
        "            diffs = df[date_col].diff().dropna()\n",
        "            if len(diffs) > 0:\n",
        "                delta = diffs.mode()[0]\n",
        "\n",
        "                # Common frequency patterns\n",
        "                if pd.Timedelta(hours=23) <= delta <= pd.Timedelta(hours=25):\n",
        "                    return 'D'\n",
        "                elif pd.Timedelta(days=6) <= delta <= pd.Timedelta(days=8):\n",
        "                    return 'W'\n",
        "                elif pd.Timedelta(days=28) <= delta <= pd.Timedelta(days=31):\n",
        "                    return 'M'\n",
        "                elif pd.Timedelta(days=89) <= delta <= pd.Timedelta(days=92):\n",
        "                    return 'Q'\n",
        "                elif pd.Timedelta(days=364) <= delta <= pd.Timedelta(days=366):\n",
        "                    return 'Y'\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Frequency detection warning: {{str(e)}}\")\n",
        "\n",
        "        return 'D'  # Default fallback\n",
        "\n",
        "    # ================================\n",
        "    # Enhanced Model Evaluation\n",
        "    # ================================\n",
        "    def evaluate_model(model_func, train, test, value_col):\n",
        "        \"\"Comprehensive model evaluation with multiple metrics\"\"\n",
        "        try:\n",
        "            forecast = model_func(train, value_col)\n",
        "\n",
        "            # Calculate multiple error metrics\n",
        "            mae = mean_absolute_error(test[value_col], forecast)\n",
        "            mse = mean_squared_error(test[value_col], forecast)\n",
        "            rmse = np.sqrt(mse)\n",
        "\n",
        "            # Calculate MASE\n",
        "            naive_errors = np.abs(np.diff(train[value_col]))\n",
        "            mase = mae / np.mean(naive_errors) if len(naive_errors) > 0 else float('inf')\n",
        "\n",
        "            return {{\n",
        "                'mae': mae,\n",
        "                'mse': mse,\n",
        "                'rmse': rmse,\n",
        "                'mase': mase\n",
        "            }}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Model evaluation failed: {{str(e)}}\")\n",
        "            return {{\n",
        "                'mae': float('inf'),\n",
        "                'mse': float('inf'),\n",
        "                'rmse': float('inf'),\n",
        "                'mase': float('inf')\n",
        "            }}\n",
        "\n",
        "    # ================================\n",
        "    # Multi-Seasonal Decomposition\n",
        "    # ================================\n",
        "    def detect_seasonality(df, value_col, freq):\n",
        "        \"\"Advanced seasonality detection with multiple patterns\"\"\n",
        "        periods = []\n",
        "        min_samples = 2  # Minimum cycles needed to detect seasonality\n",
        "\n",
        "        if freq == 'D':\n",
        "            if len(df) >= 14:  # 2 weeks\n",
        "                periods.append(7)  # Weekly\n",
        "            if len(df) >= 60:  # ~2 months\n",
        "                periods.append(30)  # Monthly\n",
        "        elif freq == 'W':\n",
        "            if len(df) >= 104:  # 2 years\n",
        "                periods.append(52)  # Yearly\n",
        "        elif freq == 'M':\n",
        "            periods.append(12)  # Yearly\n",
        "            if len(df) >= 24:  # 2 years\n",
        "                periods.append(3)  # Quarterly\n",
        "\n",
        "        return periods\n",
        "\n",
        "    # ================================\n",
        "    # Enhanced Forecasting Models\n",
        "    # ================================\n",
        "    def forecast_with_prophet(df, value_col, date_col, periods, seasonality):\n",
        "        \"\"Robust Prophet implementation with error handling\"\"\n",
        "        try:\n",
        "            df = df.copy()\n",
        "            df = df.rename(columns={{date_col: 'ds', value_col: 'y'}})\n",
        "\n",
        "            m = Prophet(\n",
        "                yearly_seasonality='auto',\n",
        "                weekly_seasonality='auto',\n",
        "                daily_seasonality='auto',\n",
        "                interval_width=0.95\n",
        "            )\n",
        "\n",
        "            # Add detected seasonalities\n",
        "            for period in seasonality:\n",
        "                if period == 7:\n",
        "                    m.add_seasonality(name='weekly', period=7, fourier_order=3)\n",
        "                elif period == 12:\n",
        "                    m.add_seasonality(name='yearly', period=365.25, fourier_order=5)\n",
        "                elif period == 3:\n",
        "                    m.add_seasonality(name='quarterly', period=91.25, fourier_order=3)\n",
        "\n",
        "            m.fit(df)\n",
        "            future = m.make_future_dataframe(\n",
        "                periods=periods,\n",
        "                freq=detect_frequency(df, 'ds'),\n",
        "                include_history=False\n",
        "            )\n",
        "            forecast = m.predict(future)\n",
        "\n",
        "            return forecast.rename(columns={{\n",
        "                'ds': date_col,\n",
        "                'yhat': 'forecast',\n",
        "                'yhat_lower': 'forecast_lower',\n",
        "                'yhat_upper': 'forecast_upper'\n",
        "            }})[[date_col, 'forecast', 'forecast_lower', 'forecast_upper']]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Prophet failed: {{str(e)}}\")\n",
        "            return None\n",
        "\n",
        "    def forecast_with_sarimax(df, value_col, seasonal_order):\n",
        "        \"\"Robust SARIMAX implementation with error handling\"\"\n",
        "        try:\n",
        "            model = SARIMAX(\n",
        "                df[value_col],\n",
        "                order=(1,1,1),\n",
        "                seasonal_order=seasonal_order,\n",
        "                enforce_stationarity=False,\n",
        "                enforce_invertibility=False\n",
        "            )\n",
        "            results = model.fit(disp=False)\n",
        "            forecast = results.get_forecast(steps=seasonal_order[3])\n",
        "            return pd.DataFrame({{\n",
        "                'forecast': forecast.predicted_mean,\n",
        "                'forecast_lower': forecast.conf_int().iloc[:,0],\n",
        "                'forecast_upper': forecast.conf_int().iloc[:,1]\n",
        "            }})\n",
        "        except Exception as e:\n",
        "            print(f\"SARIMAX failed: {{str(e)}}\")\n",
        "            return None\n",
        "\n",
        "    # ================================\n",
        "    # Main Forecasting Logic\n",
        "    # ================================\n",
        "    def generate_forecast(df, date_col, value_col, id_col, forecast_horizon):\n",
        "        \"\"Complete forecasting pipeline with fallbacks\"\"\n",
        "        try:\n",
        "            validate_input_data(df)\n",
        "            df = prepare_data(df, date_col, value_col)\n",
        "            freq = detect_frequency(df, date_col)\n",
        "            seasonality = detect_seasonality(df, value_col, freq)\n",
        "\n",
        "            # Available models with weights\n",
        "            models = [\n",
        "                ('Prophet', lambda: forecast_with_prophet(\n",
        "                    df, value_col, date_col, forecast_horizon, seasonality), 0.5),\n",
        "                ('SARIMAX', lambda: forecast_with_sarimax(\n",
        "                    df, value_col, (1,1,1,seasonality[0] if seasonality else 12)), 0.3),\n",
        "                ('ExponentialSmoothing', lambda: ExponentialSmoothing(\n",
        "                    df[value_col], seasonal=seasonality[0] if seasonality else None\n",
        "                ).fit().forecast(forecast_horizon), 0.2)\n",
        "            ]\n",
        "\n",
        "            # Evaluate models\n",
        "            best_model = None\n",
        "            best_score = float('inf')\n",
        "            tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "            for name, model_fn, weight in models:\n",
        "                try:\n",
        "                    scores = []\n",
        "                    for train_idx, test_idx in tscv.split(df):\n",
        "                        train, test = df.iloc[train_idx], df.iloc[test_idx]\n",
        "                        result = evaluate_model(model_fn, train, test, value_col)\n",
        "                        scores.append(result['mase'])\n",
        "\n",
        "                    avg_score = np.mean(scores) * (1/weight)  # Weighted score\n",
        "                    if avg_score < best_score:\n",
        "                        best_score = avg_score\n",
        "                        best_model = model_fn\n",
        "                except Exception as e:\n",
        "                    print(f\"Model {{name}} failed during evaluation: {{str(e)}}\")\n",
        "\n",
        "            # Generate final forecast\n",
        "            if best_model:\n",
        "                forecast = best_model()\n",
        "                if forecast is not None:\n",
        "                    forecast['id'] = id_col\n",
        "                    return forecast\n",
        "\n",
        "            # Fallback to simple moving average if all models fail\n",
        "            print(\"All models failed, using simple moving average fallback\")\n",
        "            return pd.DataFrame({{\n",
        "                date_col: pd.date_range(\n",
        "                    start=df[date_col].max(),\n",
        "                    periods=forecast_horizon+1,\n",
        "                    freq=detect_frequency(df, date_col)\n",
        "                )[1:],\n",
        "                'forecast': df[value_col].rolling(3).mean().iloc[-forecast_horizon:].values,\n",
        "                'id': id_col\n",
        "            }})\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Forecasting pipeline failed: {{str(e)}}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    # ================================\n",
        "    # Final Implementation\n",
        "    # ================================\n",
        "    try:\n",
        "        df = pd.DataFrame(data)\n",
        "        date_col, value_col, id_col = detect_columns(df)\n",
        "\n",
        "        # Determine forecast horizon based on data frequency\n",
        "        freq = detect_frequency(df, date_col)\n",
        "        forecast_horizon = {{\n",
        "            'D': 14,   # 2 weeks\n",
        "            'W': 8,    # 2 months\n",
        "            'M': 12,   # 1 year\n",
        "            'Q': 4,    # 1 year\n",
        "            'Y': 2     # 2 years\n",
        "        }}.get(freq, 12)  # Default to 12 periods\n",
        "\n",
        "        # Generate forecast\n",
        "        forecast_df = generate_forecast(df, date_col, value_col, id_col, forecast_horizon)\n",
        "\n",
        "        # Ensure output format consistency\n",
        "        required_cols = [date_col, 'forecast', 'forecast_lower', 'forecast_upper', 'id']\n",
        "        for col in required_cols:\n",
        "            if col not in forecast_df.columns:\n",
        "                forecast_df[col] = None  # Add missing columns with nulls\n",
        "\n",
        "        return forecast_df[required_cols]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Critical error in forecast_ts: {{str(e)}}\")\n",
        "        return pd.DataFrame()  # Return empty DataFrame on complete failure\n",
        "\n",
        "\n",
        "# **ERROR PREVENTION MEASURES**:\n",
        "1. Comprehensive input validation\n",
        "2. Multiple fallback strategies for column detection\n",
        "3. Robust data cleaning and preparation\n",
        "4. Multiple model options with weighted evaluation\n",
        "5. Graceful degradation when models fail\n",
        "6. Consistent output format enforcement\n",
        "7. Detailed error logging at each step\n",
        "\n",
        "# **RETURN**:\n",
        "  - Return Python code wrapped in ```python```\n",
        "  - The function must handle all edge cases gracefully\n",
        "  - Output DataFrame must always contain: date_col, forecast, forecast_lower, forecast_upper, id\n",
        "\n",
        "# **INPUTS**:\n",
        "  - Data sample: {data}\n",
        "  - User's Forecast Question: {question}\n",
        "\"\"\",\n",
        "    input_variables=[\"question\", \"data\"]\n",
        ")\n",
        "\n",
        "### Making a Custom output structure for python code\n",
        "\n",
        "import re\n",
        "\n",
        "class PythonOutputParser(BaseOutputParser[str]):\n",
        "    \"\"\"Parse the output of an LLM call to a Python code block.\"\"\"\n",
        "\n",
        "    def parse(self, text: str) -> str:\n",
        "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
        "        # Find the first occurrence of a Python code block\n",
        "        match = re.search(r\"```python\\n(.*?)\\n```\", text, re.DOTALL)\n",
        "\n",
        "        if match:\n",
        "            # Extract the content within the code block\n",
        "            python_code = match.group(1).strip()\n",
        "            return python_code\n",
        "        else:\n",
        "            # If no code block is found, return the original text or an empty string\n",
        "            return text.strip() # Or return \"\" depending on desired behavior\n",
        "\n",
        "forecast_generator=forecast_code_prompt | llm | PythonOutputParser()\n",
        "\n",
        "\n",
        "# 3- Data Analyst agent\n",
        "\n",
        "data_questions_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a Data Analysis Expert specialized in time series forecasting. Your task is to:\n",
        "1. Analyze the user's question about forecasting data\n",
        "2. Generate Python code to answer the question using the provided data\n",
        "3. Return clean, executable Python code that produces the requested analysis\n",
        "\n",
        "# GUIDELINES:\n",
        "- Always work with the provided data (don't create synthetic data)\n",
        "- Include all necessary imports within the function\n",
        "- Handle missing/incorrect data gracefully\n",
        "- Return a pandas DataFrame with the results\n",
        "- Make the code reusable and well-commented\n",
        "\n",
        "# COMMON QUESTION TYPES TO HANDLE:\n",
        "1. Data Exploration:\n",
        "   - Summary statistics\n",
        "   - Missing value analysis\n",
        "   - Time period coverage\n",
        "   - Outlier detection\n",
        "\n",
        "2. Forecasting Preparation:\n",
        "   - Resampling time series\n",
        "   - Handling missing dates\n",
        "   - Feature engineering\n",
        "   - Stationarity tests\n",
        "\n",
        "3. Forecast Analysis:\n",
        "   - Model comparisons\n",
        "   - Error metrics\n",
        "   - Confidence intervals\n",
        "   - Residual analysis\n",
        "\n",
        "4. Data Transformations:\n",
        "   - Normalization/scaling\n",
        "   - Differencing\n",
        "   - Log transformations\n",
        "   - Rolling statistics\n",
        "\n",
        "# OUTPUT FORMAT:\n",
        "```python\n",
        "def analyze_forecast_data(data):\n",
        "    \\\"\\\"\\\"\n",
        "    Analyzes forecasting data based on user question.\n",
        "\n",
        "    Args:\n",
        "        data: Input data as dictionary (will be converted to DataFrame)\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame with analysis results\n",
        "    \\\"\\\"\\\"\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from statsmodels.tsa.stattools import adfuller\n",
        "    # Other necessary imports...\n",
        "\n",
        "    # Convert input to DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # [Your analysis code here]\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# EXAMPLE QUESTIONS:\n",
        "\"What's the monthly average of the time series?\"\n",
        "\n",
        "\"Are there any missing dates in the time series?\"\n",
        "\n",
        "\"Show me the rolling 7-day average\"\n",
        "\n",
        "\"Is the time series stationary?\"\n",
        "\n",
        "\"What's the autocorrelation structure?\"\n",
        "\n",
        "CURRENT QUESTION:\n",
        "{question}\n",
        "\n",
        "DATA SAMPLE (first 5 rows):\n",
        "{data_head}\n",
        "\n",
        "COLUMNS IN DATA:\n",
        "{columns}\n",
        "\n",
        "# IMPORTANT:\n",
        "Wrap your code in python delimiters\n",
        "\n",
        "The function must be named analyze_forecast_data\n",
        "\n",
        "Return a DataFrame even for single-value results\n",
        "\"\"\",\n",
        "input_variables=[\"question\", \"data_head\", \"columns\"]\n",
        ")\n",
        "\n",
        "data_questions_agent = data_questions_prompt | llm | PythonOutputParser()\n",
        "\n",
        "# Visulization Function\n",
        "\n",
        "## Using LLM to detect columns to plot\n",
        "\n",
        "column_detection_prompt = PromptTemplate(\n",
        "    template=\"\"\"Analyze the following DataFrame columns and identify:\n",
        "    1. The datetime column (most likely to contain dates/times)\n",
        "    2. The value column (numeric column to be visualized)\n",
        "\n",
        "    Return JSON with:\n",
        "    - \"date_column\": name of the datetime column\n",
        "    - \"value_column\": name of the numeric value column\n",
        "\n",
        "    Available columns: {columns}\n",
        "    First row sample: {first_row}\n",
        "\n",
        "    Focus on these common patterns:\n",
        "    - Date columns often have names like: date, time, timestamp, datetime\n",
        "    - Value columns are typically numeric and have names like: value, sales, price, quantity\n",
        "\n",
        "    If uncertain, choose the most likely candidates.\"\"\",\n",
        "    input_variables=[\"columns\", \"first_row\"]\n",
        ")\n",
        "\n",
        "column_detection_chain = column_detection_prompt | llm | JsonOutputParser()\n",
        "\n",
        "from typing import Dict\n",
        "from plotly import graph_objects as go\n",
        "\n",
        "def detect_columns(df: pd.DataFrame) -> Dict[str, str]:\n",
        "    \"\"\"Enhanced column detection with better fallback logic\"\"\"\n",
        "    columns = list(df.columns)\n",
        "\n",
        "    # Try LLM detection first\n",
        "    try:\n",
        "        first_row = df.iloc[0].to_dict()\n",
        "        result = column_detection_chain.invoke({\n",
        "            \"columns\": columns,\n",
        "            \"first_row\": first_row\n",
        "        })\n",
        "        return {\n",
        "            \"date_column\": result[\"date_column\"],\n",
        "            \"value_column\": result[\"value_column\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"LLM column detection failed, using fallback: {str(e)}\")\n",
        "\n",
        "    # Enhanced fallback logic\n",
        "    date_col = None\n",
        "    value_col = None\n",
        "\n",
        "    # Check common date column names\n",
        "    date_candidates = ['date', 'time', 'timestamp', 'datetime', 'ds']\n",
        "    for col in df.columns:\n",
        "        if col.lower() in date_candidates:\n",
        "            date_col = col\n",
        "            break\n",
        "\n",
        "    # If no obvious date column found, try to infer\n",
        "    if date_col is None:\n",
        "        for col in df.columns:\n",
        "            try:\n",
        "                if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
        "                    date_col = col\n",
        "                    break\n",
        "                pd.to_datetime(df[col])  # Test if convertible\n",
        "                date_col = col\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    # Find value column - look for numeric columns\n",
        "    numeric_cols = df.select_dtypes(include='number').columns\n",
        "    if len(numeric_cols) > 0:\n",
        "        value_col = numeric_cols[0]  # Use first numeric column\n",
        "\n",
        "    if date_col is None or value_col is None:\n",
        "        raise ValueError(\n",
        "            f\"Could not detect required columns. Date candidates: {date_col}, \"\n",
        "            f\"Value candidates: {value_col}. Available columns: {columns}\"\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"date_column\": date_col,\n",
        "        \"value_column\": value_col\n",
        "    }\n",
        "\n",
        "def create_visualization(state: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Creates an interactive Plotly line plot for the forecast.\n",
        "    Automatically detects date and value columns using LLM.\n",
        "    \"\"\"\n",
        "    if 'plotly_figure' in state and state['plotly_figure'] is not None:\n",
        "        return state\n",
        "\n",
        "    print(\"Generating Interactive Forecast Visualization\")\n",
        "\n",
        "    # Convert data from state\n",
        "    forecast_df = pd.DataFrame(state['data_forecast'])\n",
        "\n",
        "    # Detect columns in forecast data\n",
        "    forecast_cols = detect_columns(forecast_df)\n",
        "    date_col = forecast_cols[\"date_column\"]\n",
        "    value_col = forecast_cols[\"value_column\"]\n",
        "\n",
        "    if not date_col or not value_col:\n",
        "        raise ValueError(\"Could not detect required columns (date and value)\")\n",
        "\n",
        "    # Process date columns\n",
        "    forecast_df[date_col] = pd.to_datetime(forecast_df[date_col])\n",
        "\n",
        "    # Create Plotly figure\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add forecast trace\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=forecast_df[date_col],\n",
        "            y=forecast_df[value_col],\n",
        "            mode='lines',\n",
        "            name='Forecast',\n",
        "            line=dict(color='#ff7f0e', width=2),\n",
        "            hovertemplate='%{x|%Y-%m-%d}<br>%{y:.2f}<extra></extra>'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Add layout configuration\n",
        "    fig.update_layout(\n",
        "        title='Time Series Forecast',\n",
        "        xaxis_title=date_col,\n",
        "        yaxis_title=value_col,\n",
        "        hovermode='x unified',\n",
        "        plot_bgcolor='white',\n",
        "        margin=dict(l=20, r=20, t=60, b=20),\n",
        "        legend=dict(\n",
        "            orientation='h',\n",
        "            yanchor='bottom',\n",
        "            y=1.02,\n",
        "            xanchor='right',\n",
        "            x=1\n",
        "        ),\n",
        "        xaxis=dict(\n",
        "            showgrid=True,\n",
        "            gridcolor='lightgray',\n",
        "            gridwidth=1,\n",
        "            tickformat='%Y-%m-%d'\n",
        "        ),\n",
        "        yaxis=dict(\n",
        "            showgrid=True,\n",
        "            gridcolor='lightgray',\n",
        "            gridwidth=1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Store both the figure object and its data\n",
        "    return {\n",
        "        **state,\n",
        "        \"visualization\": {\n",
        "            \"figure_data\": {\n",
        "                \"dates\": forecast_df[date_col].dt.strftime('%Y-%m-%d').tolist(),\n",
        "                \"values\": forecast_df[value_col].tolist(),\n",
        "                \"date_col\": date_col,\n",
        "                \"value_col\": value_col\n",
        "            },\n",
        "            \"plotly_figure\": fig\n",
        "        },\n",
        "        \"plotly_figure\": fig,\n",
        "        \"date_column\": date_col,\n",
        "        \"value_column\": value_col\n",
        "    }\n",
        "\n",
        "def display_visualization(state: Dict) -> Dict:\n",
        "    \"\"\"Displays the Plotly figure and returns unmodified state\"\"\"\n",
        "    if 'visualization_displayed' not in state:\n",
        "        fig = state.get('plotly_figure')\n",
        "        if fig:\n",
        "            display(fig)\n",
        "            return {**state, \"visualization_displayed\": True}\n",
        "    return state\n",
        "\n",
        "# Using Langraph to connect the workflow\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Dict, Optional\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    user_question: str\n",
        "    data_sample_sql: dict\n",
        "    data_sql: dict\n",
        "    forecast_code: str\n",
        "    data_sample_forecast: dict\n",
        "    data_forecast: dict\n",
        "    visualization: Optional[Dict[str, Dict[str, list] | go.Figure]]\n",
        "    plotly_figure: Optional[go.Figure]\n",
        "    date_column: Optional[str]\n",
        "    value_column: Optional[str]\n",
        "    is_data_question: bool\n",
        "    routing_reason: Optional[str]\n",
        "    data_analysis_code: Optional[str]\n",
        "    data_analysis_results: Optional[dict]\n",
        "\n",
        "def preprocess_question(state: GraphState) -> GraphState:\n",
        "    question = state['user_question']\n",
        "\n",
        "    # Get classification from LLM\n",
        "    try:\n",
        "        classification = forecast_preprocessor.invoke({\"question\": question})\n",
        "        is_data_question = classification[\"question_type\"] == \"DATA_ANALYSIS\"\n",
        "\n",
        "        # If forecast question, get formatted version\n",
        "        if not is_data_question:\n",
        "            response = forecast_preprocessor.invoke({\"question\": question})\n",
        "            return {\n",
        "                **state,\n",
        "                \"is_data_question\": False,\n",
        "                \"routing_reason\": classification[\"reasoning\"]\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                **state,\n",
        "                \"is_data_question\": True,\n",
        "                \"routing_reason\": classification[\"reasoning\"]\n",
        "            }\n",
        "\n",
        "    except Exception as e:\n",
        "        # Fallback to original behavior if routing fails\n",
        "        print(f\"Routing failed: {str(e)}\")\n",
        "        response = forecast_preprocessor.invoke({\"question\": question})\n",
        "        return {\n",
        "            **state,\n",
        "            \"is_data_question\": False,\n",
        "            \"routing_reason\": \"Fallback: Defaulted to forecast\"\n",
        "        }\n",
        "\n",
        "\n",
        "def handle_data_question(state: GraphState) -> GraphState:\n",
        "    if not state.get('is_data_question'):\n",
        "        return state\n",
        "\n",
        "    print(\"Handling data question...\")\n",
        "    question = state['user_question']\n",
        "    data_sample = state['data_sample_sql']\n",
        "    columns = list(pd.DataFrame(data_sample).columns)\n",
        "\n",
        "    try:\n",
        "        code = data_questions_agent.invoke({\n",
        "            \"question\": question,\n",
        "            \"data_head\": data_sample,\n",
        "            \"columns\": columns\n",
        "        })\n",
        "\n",
        "        local_vars = {}\n",
        "        global_vars = {}\n",
        "        exec(code, global_vars, local_vars)\n",
        "        analysis_fn = local_vars['analyze_forecast_data']\n",
        "        results_df = analysis_fn(state['data_sql'])\n",
        "\n",
        "        return {\n",
        "            **state,\n",
        "            \"data_analysis_code\": code,\n",
        "            \"data_analysis_results\": results_df.to_dict()\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {**state, \"error\": str(e)}\n",
        "\n",
        "\n",
        "def generate_forecast_code(state):\n",
        "  print('Forecaster Generating')\n",
        "  question=state['user_question']\n",
        "  data=state.get('data_sample_sql')\n",
        "  response=forecast_generator.invoke({\"question\": question, \"data\": data})\n",
        "  return{\n",
        "      \"forecast_code\": response\n",
        "  }\n",
        "\n",
        "# Executing Forecast Python Code\n",
        "\n",
        "def execute_forecast_code(state):\n",
        "    print('Forecaster Executing')\n",
        "    # Retrieve the generated Python code and the data from the state\n",
        "    code = state.get('forecast_code')\n",
        "    # Get the full data as a dictionary\n",
        "    data_dict = state.get('data_sql')\n",
        "    # Get the user's original question\n",
        "    user_question = state.get('user_question')\n",
        "\n",
        "    # Prepare dictionaries for executing the code in an isolated environment\n",
        "    local_vars = {}\n",
        "    global_vars = {}\n",
        "\n",
        "    # Execute the generated code. This will define the 'analyze_data' function.\n",
        "    exec(code, global_vars, local_vars)\n",
        "\n",
        "    # Call the newly defined 'analyze_data' function with the data and question\n",
        "    # The function is accessed from the local_vars dictionary\n",
        "    analysis_result_df = local_vars['forecast_ts'](data_dict)\n",
        "\n",
        "    # Return the results, including a sample and the full data, converted back to dictionaries\n",
        "    return {\n",
        "        \"data_sample_forecast\": analysis_result_df.head(1000).to_dict(),\n",
        "        \"data_forecast\": analysis_result_df.to_dict()\n",
        "    }\n",
        "\n",
        "## Defining the workflow structure\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "workflow.add_node(\"preprocess_forecast\", preprocess_question)\n",
        "workflow.add_node(\"generate_forecast_code\", generate_forecast_code)\n",
        "workflow.add_node(\"execute_forecast_code\", execute_forecast_code)\n",
        "workflow.add_node(\"create_visualization\", create_visualization)\n",
        "workflow.add_node(\"display_visualization\", display_visualization)\n",
        "workflow.add_node(\"handle_data_question\", handle_data_question)\n",
        "\n",
        "def route_question(state: GraphState) -> str:\n",
        "    if state.get('is_data_question'):\n",
        "        return \"to_data_question\"\n",
        "    return \"to_forecast\"\n",
        "\n",
        "workflow.set_entry_point('preprocess_forecast')\n",
        "workflow.add_conditional_edges(\n",
        "    \"preprocess_forecast\",\n",
        "    route_question,\n",
        "    {\n",
        "        \"to_data_question\": \"handle_data_question\",\n",
        "        \"to_forecast\": \"generate_forecast_code\"\n",
        "    }\n",
        ")\n",
        "workflow.add_edge('preprocess_forecast', 'generate_forecast_code')\n",
        "workflow.add_edge('generate_forecast_code', 'execute_forecast_code')\n",
        "workflow.add_edge('execute_forecast_code', 'create_visualization')\n",
        "workflow.add_edge('create_visualization', 'display_visualization')\n",
        "workflow.add_edge('display_visualization', END)\n",
        "workflow.add_edge(\"handle_data_question\", END)\n",
        "\n",
        "\n",
        "\n",
        "app=workflow.compile()\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import base64\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "def clean_conversation():\n",
        "    \"\"\"Remove duplicate messages from conversation\"\"\"\n",
        "    if 'conversation' not in st.session_state:\n",
        "        return\n",
        "\n",
        "    unique_messages = []\n",
        "    seen_messages = set()\n",
        "\n",
        "    for msg in st.session_state.conversation:\n",
        "        msg_key = str(msg[\"content\"]) if not isinstance(msg[\"content\"], pd.DataFrame) else str(msg[\"content\"].to_dict())\n",
        "        if msg_key not in seen_messages:\n",
        "            unique_messages.append(msg)\n",
        "            seen_messages.add(msg_key)\n",
        "\n",
        "    st.session_state.conversation = unique_messages\n",
        "\n",
        "# Set page config\n",
        "st.set_page_config(\n",
        "    page_title=\"AI Forecasting Assistant\",\n",
        "    page_icon=\"📈\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS for better visualization\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .stPlotlyChart {\n",
        "        border-radius: 10px;\n",
        "        box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .stDataFrame {\n",
        "        border-radius: 10px;\n",
        "        box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .css-1v0mbdj {\n",
        "        border-radius: 10px;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# App header\n",
        "st.title(\"📊 AI Forecasting Assistant\")\n",
        "st.markdown(\"Upload your time series data and get automated forecasts and analysis\")\n",
        "\n",
        "# Initialize session state\n",
        "if 'conversation' not in st.session_state:\n",
        "    st.session_state.conversation = []\n",
        "if 'df' not in st.session_state:\n",
        "    st.session_state.df = None\n",
        "if 'last_question_type' not in st.session_state:\n",
        "    st.session_state.last_question_type = None\n",
        "\n",
        "\n",
        "# Sidebar for file upload\n",
        "with st.sidebar:\n",
        "    st.header(\"Data Upload\")\n",
        "    uploaded_file = st.file_uploader(\n",
        "        \"Upload your CSV file\",\n",
        "        type=[\"csv\"],\n",
        "        help=\"Upload time series data with at least one date column and one numeric column\"\n",
        "    )\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        try:\n",
        "            # Read the uploaded file\n",
        "            st.session_state.df = pd.read_csv(uploaded_file)\n",
        "\n",
        "            # Basic data info\n",
        "            st.success(\"Data uploaded successfully!\")\n",
        "            st.markdown(f\"**Shape:** {st.session_state.df.shape}\")\n",
        "            st.markdown(\"**Columns:**\")\n",
        "            st.write(list(st.session_state.df.columns))\n",
        "\n",
        "            # Show sample data\n",
        "            st.markdown(\"**Sample Data:**\")\n",
        "            st.dataframe(st.session_state.df.head(3))\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error reading file: {str(e)}\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"\"\"\n",
        "    **How to use:**\n",
        "    1. Upload your time series data (CSV)\n",
        "    2. Ask questions in the chat\n",
        "    3. Get forecasts or analysis\n",
        "\n",
        "    **Example questions:**\n",
        "    - \"Show me summary statistics\"\n",
        "    - \"Is this time series stationary?\"\n",
        "    - \"Forecast prices for next 30 days\"\n",
        "    \"\"\")\n",
        "\n",
        "clean_conversation()\n",
        "# Main chat interface\n",
        "st.header(\"Chat with AI Analyst\")\n",
        "\n",
        "# Display conversation history\n",
        "for msg in st.session_state.conversation:\n",
        "    with st.chat_message(msg[\"role\"]):\n",
        "        if isinstance(msg[\"content\"], pd.DataFrame):\n",
        "            st.dataframe(msg[\"content\"])\n",
        "        elif \"plotly_figure\" in msg:\n",
        "            st.plotly_chart(msg[\"content\"], use_container_width=True)\n",
        "        else:\n",
        "            st.write(msg[\"content\"])\n",
        "\n",
        "# Chat input\n",
        "if prompt := st.chat_input(\"Ask a question about your data...\"):\n",
        "    if st.session_state.df is None:\n",
        "        st.error(\"Please upload a dataset first!\")\n",
        "        st.stop()\n",
        "\n",
        "    # Add user question to conversation\n",
        "    st.session_state.conversation.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.write(prompt)\n",
        "\n",
        "    # Show typing indicator\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        with st.spinner(\"Analyzing your question...\"):\n",
        "            try:\n",
        "                # Run the workflow\n",
        "                result = app.invoke({\n",
        "                    \"user_question\": prompt,\n",
        "                    \"data_sample_sql\": st.session_state.df.head(100).to_dict(),\n",
        "                    \"data_sql\": st.session_state.df.to_dict()\n",
        "                })\n",
        "\n",
        "                # Handle response based on question type\n",
        "                if result.get('is_data_question'):\n",
        "                    # Data analysis results\n",
        "                    analysis_df = pd.DataFrame(result.get('data_analysis_results', {}))\n",
        "\n",
        "                    # Add to conversation\n",
        "                    st.session_state.conversation.append({\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": f\"Here's the analysis for: {prompt}\",\n",
        "                    })\n",
        "                    st.session_state.conversation.append({\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": analysis_df\n",
        "                    })\n",
        "\n",
        "                    # Display in current response\n",
        "                    st.write(f\"Here's the analysis for: {prompt}\")\n",
        "                    st.dataframe(analysis_df)\n",
        "\n",
        "                else:\n",
        "                    # Forecast results\n",
        "                    forecast_df = pd.DataFrame(result.get('data_forecast', {}))\n",
        "\n",
        "                    # Add to conversation\n",
        "                    st.session_state.conversation.append({\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": f\"Forecast results for: {prompt}\",\n",
        "                    })\n",
        "                    st.session_state.conversation.append({\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": forecast_df\n",
        "                    })\n",
        "\n",
        "                    # Display forecast\n",
        "                    st.write(f\"Forecast results for: {prompt}\")\n",
        "                    st.dataframe(forecast_df)\n",
        "\n",
        "                    # Display visualization if available\n",
        "                    if result.get('plotly_figure'):\n",
        "                        st.session_state.conversation.append({\n",
        "                            \"role\": \"assistant\",\n",
        "                            \"content\": result['plotly_figure'],\n",
        "                            \"plotly_figure\": True\n",
        "                        })\n",
        "                        st.plotly_chart(result['plotly_figure'], use_container_width=True)\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"Sorry, I encountered an error: {str(e)}\"\n",
        "                st.session_state.conversation.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": error_msg\n",
        "                })\n",
        "                st.error(error_msg)\n",
        "\n",
        "\n",
        "\n",
        "# Add download button for results\n",
        "if len(st.session_state.conversation) > 0 and st.session_state.df is not None:\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    st.sidebar.header(\"Export Results\")\n",
        "\n",
        "    # Get the last assistant message with data\n",
        "    last_result = None\n",
        "    for msg in reversed(st.session_state.conversation):\n",
        "        if msg[\"role\"] == \"assistant\" and isinstance(msg.get(\"content\"), pd.DataFrame):\n",
        "            last_result = msg[\"content\"]\n",
        "            break\n",
        "\n",
        "    if last_result is not None:\n",
        "        csv = last_result.to_csv(index=False)\n",
        "        b64 = base64.b64encode(csv.encode()).decode()\n",
        "        st.sidebar.download_button(\n",
        "            label=\"Download Last Results (CSV)\",\n",
        "            data=csv,\n",
        "            file_name=\"analysis_results.csv\",\n",
        "            mime=\"text/csv\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHly9Rt8Fc7i",
        "outputId": "ac67bb00-a4db-485c-cbb3-46d9b6d9ffec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel\n",
        "!streamlit run app.py &>/dev/null&"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMLvG1S7Fl9x",
        "outputId": "19eae7bb-813e-4aaf-e493-66fb209097d6",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.125.71.60\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJWQaY-kFTUs",
        "outputId": "8c5e662a-0703-41dd-f284-f9a31620b499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.71.60:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://empty-ducks-build.loca.lt\n",
            "Forecaster Generating\n",
            "Forecaster Executing\n",
            "Warning: Missing values found in target column. Using forward fill.\n",
            "13:33:47 - cmdstanpy - INFO - Chain [1] start processing\n",
            "13:33:48 - cmdstanpy - INFO - Chain [1] done processing\n",
            "Generating Interactive Forecast Visualization\n",
            "Figure({\n",
            "    'data': [{'hovertemplate': '%{x|%Y-%m-%d}<br>%{y:.2f}<extra></extra>',\n",
            "              'line': {'color': '#ff7f0e', 'width': 2},\n",
            "              'mode': 'lines',\n",
            "              'name': 'Forecast',\n",
            "              'type': 'scatter',\n",
            "              'x': array([datetime.datetime(2017, 9, 1, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 2, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 3, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 4, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 5, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 6, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 7, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 8, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 9, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 10, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 11, 0, 0),\n",
            "                          datetime.datetime(2017, 9, 12, 0, 0)], dtype=object),\n",
            "              'y': array([48.52143345, 45.88147453, 45.95262306, 48.65675904, 48.68468781,\n",
            "                          48.73714822, 48.7699894 , 48.80467682, 46.06229982, 46.03503643,\n",
            "                          48.64740142, 48.59263192])}],\n",
            "    'layout': {'hovermode': 'x unified',\n",
            "               'legend': {'orientation': 'h', 'x': 1, 'xanchor': 'right', 'y': 1.02, 'yanchor': 'bottom'},\n",
            "               'margin': {'b': 20, 'l': 20, 'r': 20, 't': 60},\n",
            "               'plot_bgcolor': 'white',\n",
            "               'template': '...',\n",
            "               'title': {'text': 'Time Series Forecast'},\n",
            "               'xaxis': {'gridcolor': 'lightgray',\n",
            "                         'gridwidth': 1,\n",
            "                         'showgrid': True,\n",
            "                         'tickformat': '%Y-%m-%d',\n",
            "                         'title': {'text': 'date'}},\n",
            "               'yaxis': {'gridcolor': 'lightgray', 'gridwidth': 1, 'showgrid': True, 'title': {'text': 'forecast'}}}\n",
            "})\n",
            "Forecaster Generating\n",
            "Forecaster Executing\n",
            "Warning: Some dates could not be parsed. Dropping invalid rows.\n",
            "13:35:29 - cmdstanpy - INFO - Chain [1] start processing\n",
            "13:35:29 - cmdstanpy - INFO - Chain [1] done processing\n",
            "Generating Interactive Forecast Visualization\n",
            "Figure({\n",
            "    'data': [{'hovertemplate': '%{x|%Y-%m-%d}<br>%{y:.2f}<extra></extra>',\n",
            "              'line': {'color': '#ff7f0e', 'width': 2},\n",
            "              'mode': 'lines',\n",
            "              'name': 'Forecast',\n",
            "              'type': 'scatter',\n",
            "              'x': array([datetime.datetime(2012, 12, 11, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 12, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 13, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 14, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 15, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 16, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 17, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 18, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 19, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 20, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 21, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 22, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 23, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 24, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 25, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 26, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 27, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 28, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 29, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 30, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 31, 0, 0),\n",
            "                          datetime.datetime(2013, 1, 1, 0, 0),\n",
            "                          datetime.datetime(2013, 1, 2, 0, 0),\n",
            "                          datetime.datetime(2013, 1, 3, 0, 0),\n",
            "                          datetime.datetime(2013, 1, 4, 0, 0),\n",
            "                          datetime.datetime(2013, 1, 5, 0, 0),\n",
            "                          datetime.datetime(2013, 1, 6, 0, 0),\n",
            "                          datetime.datetime(2013, 1, 7, 0, 0),\n",
            "                          datetime.datetime(2013, 1, 8, 0, 0),\n",
            "                          datetime.datetime(2013, 1, 9, 0, 0)], dtype=object),\n",
            "              'y': array([1014319.87326426,  950978.43895577,  995573.24446673,  982132.69912   ,\n",
            "                           983041.49396295,  995342.87257778, 1032141.92710865, 1010658.42000581,\n",
            "                           953254.99544767, 1003386.82066812,  994920.71730555, 1000096.20494992,\n",
            "                          1015832.05572469, 1055133.29169349, 1035147.01765593,  978192.86488909,\n",
            "                          1027714.01974313, 1017596.85491357, 1020131.5685317 , 1032317.43867286,\n",
            "                          1067267.65941214, 1042262.20997511,  979774.61451976, 1023418.66913327,\n",
            "                          1007263.27434137, 1003787.91315014, 1010182.52767643, 1039746.9124201 ,\n",
            "                          1009938.22980359,  943392.65737612])}],\n",
            "    'layout': {'hovermode': 'x unified',\n",
            "               'legend': {'orientation': 'h', 'x': 1, 'xanchor': 'right', 'y': 1.02, 'yanchor': 'bottom'},\n",
            "               'margin': {'b': 20, 'l': 20, 'r': 20, 't': 60},\n",
            "               'plot_bgcolor': 'white',\n",
            "               'template': '...',\n",
            "               'title': {'text': 'Time Series Forecast'},\n",
            "               'xaxis': {'gridcolor': 'lightgray',\n",
            "                         'gridwidth': 1,\n",
            "                         'showgrid': True,\n",
            "                         'tickformat': '%Y-%m-%d',\n",
            "                         'title': {'text': 'Date'}},\n",
            "               'yaxis': {'gridcolor': 'lightgray', 'gridwidth': 1, 'showgrid': True, 'title': {'text': 'forecast'}}}\n",
            "})\n",
            "Forecaster Generating\n",
            "Handling data question...\n",
            "Forecaster Executing\n",
            "Warning: Some dates could not be parsed. Dropping invalid rows.\n",
            "Generating Interactive Forecast Visualization\n",
            "Figure({\n",
            "    'data': [{'hovertemplate': '%{x|%Y-%m-%d}<br>%{y:.2f}<extra></extra>',\n",
            "              'line': {'color': '#ff7f0e', 'width': 2},\n",
            "              'mode': 'lines',\n",
            "              'name': 'Forecast',\n",
            "              'type': 'scatter',\n",
            "              'x': array([datetime.datetime(2012, 12, 11, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 12, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 13, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 14, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 15, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 16, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 17, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 18, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 19, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 20, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 21, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 22, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 23, 0, 0),\n",
            "                          datetime.datetime(2012, 12, 24, 0, 0)], dtype=object),\n",
            "              'y': array([1023789.12666667, 1023789.12666667, 1023789.12666667, 1023789.12666667,\n",
            "                          1023789.12666667, 1023789.12666667, 1023789.12666667, 1023789.12666667,\n",
            "                          1023789.12666667, 1023789.12666667, 1023789.12666667, 1023789.12666667,\n",
            "                          1023789.12666667, 1023789.12666667])}],\n",
            "    'layout': {'hovermode': 'x unified',\n",
            "               'legend': {'orientation': 'h', 'x': 1, 'xanchor': 'right', 'y': 1.02, 'yanchor': 'bottom'},\n",
            "               'margin': {'b': 20, 'l': 20, 'r': 20, 't': 60},\n",
            "               'plot_bgcolor': 'white',\n",
            "               'template': '...',\n",
            "               'title': {'text': 'Time Series Forecast'},\n",
            "               'xaxis': {'gridcolor': 'lightgray',\n",
            "                         'gridwidth': 1,\n",
            "                         'showgrid': True,\n",
            "                         'tickformat': '%Y-%m-%d',\n",
            "                         'title': {'text': 'Date'}},\n",
            "               'yaxis': {'gridcolor': 'lightgray', 'gridwidth': 1, 'showgrid': True, 'title': {'text': 'forecast'}}}\n",
            "})\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "etsMCYj04f8U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNE3MY5F9JesDNjPFmgHXOb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}